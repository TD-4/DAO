
# -*- coding: utf-8 -*-
# @Author:FelixFu
# @Date: 2021.12.17
# @GitHub:https://github.com/felixfu520
# @Copy From: https://github.com/xiahaifeng1995/PaDiM-Anomaly-Detection-Localization-master/blob/main/datasets/mvtec.py

import os
import numpy as np
from PIL import Image
from loguru import logger

from torch.utils.data import Dataset

from core.modules.register import Registers


@Registers.datasets.register
class MVTecDataset(Dataset):
    def __init__(self,
                 data_dir=None,
                 preproc=None,
                 image_set="",
                 in_channels=1,
                 cache=False,
                 image_suffix=".png",
                 mask_suffix=".png",
                 **kwargs
                 ):
        """
        å¼‚å¸¸æ£€æµ‹æ•°æ®é›†ï¼Œï¼ˆMVTecDatasetç±»åž‹ï¼‰

        data_dir:str  æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„ï¼Œæ–‡ä»¶å¤¹è¦æ±‚æ˜¯
            ðŸ“‚datasets æ•°æ®é›†åç§°
              â”£ ðŸ“‚ ground_truth  testæµ‹è¯•æ–‡ä»¶å¤¹å¯¹åº”çš„mask
              â”ƒ     â”£ ðŸ“‚ defective_type_1    å¼‚å¸¸ç±»åˆ«1 maskï¼ˆ0ï¼Œ255ï¼‰
              â”ƒ     â”— ðŸ“‚ defective_type_2    å¼‚å¸¸ç±»åˆ«2 mask
              â”£ ðŸ“‚ test  æµ‹è¯•æ–‡ä»¶å¤¹
              â”ƒ     â”£ ðŸ“‚ defective_type_1    å¼‚å¸¸ç±»åˆ«1 å›¾ç‰‡
              â”ƒ     â”£ ðŸ“‚ defective_type_2    å¼‚å¸¸ç±»åˆ«2 å›¾ç‰‡
              â”ƒ     â”— ðŸ“‚ good
              â”— ðŸ“‚ train è®­ç»ƒæ–‡ä»¶å¤¹
              â”ƒ     â”— ðŸ“‚ good

        preproc:albumentations.Compose å¯¹å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†
        image_set:str "train.txt or val.txt or test.txt"ï¼› train.txtæ˜¯è®­ç»ƒï¼Œå…¶ä½™æ˜¯æµ‹è¯•
        in_channels:int  è¾“å…¥å›¾ç‰‡çš„é€šé“æ•°ï¼Œç›®å‰åªæ”¯æŒ1å’Œ3é€šé“
        cache:bool æ˜¯å¦å¯¹å›¾ç‰‡è¿›è¡Œå†…å­˜ç¼“å­˜
        image_suffix:str å¯æŽ¥å—çš„å›¾ç‰‡åŽç¼€
        mask_suffix:str å¯æŽ¥å—çš„å›¾ç‰‡åŽç¼€
        """
        # set attr
        self.root = data_dir
        self.preproc = preproc
        self.is_train = True if image_set == "train.txt" else False
        self.in_channels = in_channels
        self.image_suffix = image_suffix
        self.mask_suffix = mask_suffix

        # å­˜å‚¨image-mask pair
        self.x, self.y, self.mask = self.load_dataset_folder()  # xå­˜æ”¾å›¾ç‰‡çš„è·¯å¾„ï¼›yæ ‡å¿—æ­¤å›¾ç‰‡æ˜¯å¦æ˜¯goodï¼Œgoodä¸º0ï¼Œéžgoodä¸º1ï¼›maskå­˜æ”¾maskå›¾ç‰‡è·¯å¾„ï¼Œgoodä¸ºç©ºï¼›

        if cache:
            logger.warning("MVTecDataset not supported cache !")

    def __getitem__(self, index):
        image, mask, label, image_path = self.pull_item(index)  # image:ndarray, å›¾ç‰‡ï¼›mask:ndarray,æŽ©ç ï¼›label:intï¼Œæ˜¯å¦æœ‰maskï¼› image_path:stringï¼Œå›¾ç‰‡è·¯å¾„
        if self.preproc is not None:
            transformed = self.preproc(image=image, mask=mask)
            image, mask = transformed['image'], transformed["mask"]
        image = image.transpose(2, 0, 1)  # c, h, w
        mask = mask.astype(np.int64)
        return image, mask, label, image_path  # image:ndarray, å›¾ç‰‡ï¼›mask:ndarray,æŽ©ç ï¼›label:intï¼Œæ˜¯å¦æœ‰maskï¼› image_path:stringï¼Œå›¾ç‰‡è·¯å¾„

    def pull_item(self, index):
        img, mask = self._load_img(index)
        if self.in_channels == 1:
            img = np.expand_dims(img.copy(), axis=2)
        elif self.in_channels == 3:
            img = img.copy()
        return img, mask, self.y[index], self.x[index]

    def _load_img(self, index):
        image_path = self.x[index]
        has_mask = self.y[index]
        mask_path = self.mask[index]

        # get image
        image = None
        if self.in_channels == 1:
            image = Image.open(image_path).convert('L')
        elif self.in_channels == 3:
            image = Image.open(image_path)
        image = np.array(image)

        # get mask
        if has_mask == 0:
            mask = np.zeros(image.shape[:2])
        else:
            mask = Image.open(mask_path)
            mask = np.array(mask)

        return image, mask

    def load_dataset_folder(self):
        phase = 'train' if self.is_train else 'test'
        x, y, mask = [], [], []     # xå­˜æ”¾å›¾ç‰‡çš„è·¯å¾„ï¼Œyæ ‡å¿—æ­¤å›¾ç‰‡æ˜¯å¦æ˜¯goodï¼ˆ0ï¼‰ï¼Œmaskå­˜æ”¾maskå›¾ç‰‡è·¯å¾„

        # èŽ·å¾—datasetç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å¤¹ï¼Œå³trainã€testã€ground_truth
        img_dir = os.path.join(self.root, phase)    # è®­ç»ƒé›†æˆ–æµ‹è¯•é›†æ–‡ä»¶å¤¹
        gt_dir = os.path.join(self.root, 'ground_truth')    # çœŸå®žmaskæ–‡ä»¶å¤¹

        # å¦‚æžœæ˜¯trainï¼Œåˆ™åªæœ‰good
        # å¦‚æžœæ˜¯testï¼Œåˆ™æœ‰goodã€å…¶ä»–å¼‚å¸¸ç±»åˆ«
        img_types = sorted(os.listdir(img_dir))  # goodã€å…¶ä»–å¼‚å¸¸ç±»åˆ«
        for img_type in img_types:  # å¤„ç†æ¯ä¸ªå¼‚å¸¸ç±»åˆ«ï¼ˆåŒ…æ‹¬goodï¼‰ï¼Œtrainå’Œtestæƒ…å†µã€‚
            # load images
            img_type_dir = os.path.join(img_dir, img_type)
            if not os.path.isdir(img_type_dir):
                continue
            # éåŽ†å…¶ä¸­ä¸€ä¸ªç±»åˆ«ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
            img_fpath_list = sorted([os.path.join(img_type_dir, f)
                                     for f in os.listdir(img_type_dir)
                                     if f.endswith(self.image_suffix)])
            x.extend(img_fpath_list)

            # load gt labels
            if img_type == 'good':
                y.extend([0] * len(img_fpath_list))
                mask.extend([None] * len(img_fpath_list))
            else:
                y.extend([1] * len(img_fpath_list))
                gt_type_dir = os.path.join(gt_dir, img_type)
                img_fname_list = [os.path.splitext(os.path.basename(f))[0] for f in img_fpath_list]
                gt_fpath_list = [os.path.join(gt_type_dir, img_fname + '_mask' + self.mask_suffix)
                                 for img_fname in img_fname_list]
                mask.extend(gt_fpath_list)

        assert len(x) == len(y), 'number of x and y should be same'

        return list(x), list(y), list(mask)

    def __len__(self):
        return len(self.x)

    def __repr__(self):
        fmt_str = "Dataset:" + self.__class__.__name__
        fmt_str += "; Length:{}".format(self.__len__())
        fmt_str += "; Data_dir:{}".format(self.root)
        return fmt_str


if __name__ == "__main__":
    from core.modules.dataloaders.augments import get_transformer
    from dotmap import DotMap
    dataset_c = {
        "type": "MVTecDataset",
        "kwargs": {
            "data_dir": "/root/data/DAO/mvtec_anomaly_detection/bottle",
            "image_set": "test.txt",
            "in_channels": 3,
            "cache": True,
            "image_suffix": ".png",
            "mask_suffix": ".png"
        },
        "transforms": {
            "kwargs": {
                "Resize": {"height": 224, "width": 224, "p": 1, "interpolation": 0},
                "Normalize": {"mean": 0, "std": 1, "p": 1}


            }
        }
    }
    dataset_c = DotMap(dataset_c)
    transformer = get_transformer(dataset_c.transforms.kwargs)
    dataset = MVTecDataset(preproc=transformer, **dataset_c.kwargs)

    for i in range(len(dataset)):
        img, mask, label, img_p = dataset.__getitem__(i)
        print("image path:{}-->mask unique:{}".format(img_p, np.unique(mask)))
