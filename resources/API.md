# API

## 1. models

### Unet

[source](../core/modules/models/seg/unet/model.py)

**æ„é€ å‡½æ•°**

```
class Unet( encoder,
            encoder_depth=5,
            encoder_channels=None,
            decoder_use_batchnorm: bool = True,
            decoder_channels: List[int] = (256, 128, 64, 32, 16),
            decoder_attention_type: Optional[str] = None,
            num_classes=2,
            activation: Optional[Union[str, callable]] = None,
            aux_params: Optional[dict] = None,
    )
"""
encoder: dict encoderçš„é…ç½®å­—å…¸
encoder_depth: encoderæ·±åº¦
encoder_channels: encoder çš„æ¯ä¸€å±‚channelæ•°
decoder_use_batchnorm: bool
decoder_channels: List[int] = (256, 128, 64, 32, 16),
decoder_attention_type: Optional[str] = None,
num_classes=2,
activation: Optional[Union[str, callable]] = None,
aux_params: Optional[dict] = None,
"""
```

**configs.json**

```
"model": {
        "type": "Unet",
        "summary_size": [3,224,224],
        "backbone": {
            "kwargs": {
                "model_name": "resnet18",
                "pretrained": true,
                "checkpoint_path": "",
                "exportable": true,
                "in_chans": 3,
                "features_only": true
            }
        },
        "kwargs": {
            "encoder_depth": 5,
            "encoder_channels": [3, 64, 64, 128, 256, 512],
            "decoder_channels": [256, 128, 64, 32, 16],
            "num_classes": 21
        }
    }
```

## 2. optims

### sgd_warmup_bias_bn_weight

[source](../core/modules/optims/sgd_warmup_bias_bn_weight.py)

**æ„é€ å‡½æ•°**

```
def sgd_warmup_bias_bn_weight(model=None,
                              lr=0.01,
                              weight_decay=1e-4,
                              momentum=0.9,
                              warmup_lr=0,
                              warmup_epoch=5
                              ):
    """
    model:torch.nn.Module æ­¤trainerçš„self.modelå±æ€§
    lr: float å¯¹äºæ•´ä¸ªï¼ˆå¤šæœºå¤šå¡ï¼‰batch sizeçš„å­¦ä¹ ç‡
    weight_decay:float torch.optim.SGD é»˜è®¤å‚æ•°
    momentum:float torch.optim.SGD é»˜è®¤å‚æ•°
    warmup_lr:float warmupæ—¶çš„å­¦ä¹ ç‡
    warmup_epoch:int warmupå‡ ä¸ªepoch
    """
```

**configs.json**

```
   "optimizer": {
        "type": "sgd_warmup_bias_bn_weight",
        "kwargs": {
            "lr": 0.01,
            "weight_decay": 1e-4,
            "momentum": 0.9,
            "warmup_lr": 0,
            "warmup_epoch": 5
        }
    }
```

## 3. datasets & dataloaders

### SegDataset

[source](../core/modules/dataloaders/datasets/SegDataset.py)

**æ„é€ å‡½æ•°**

```
Class SegDataset(data_dir=None, preproc=None, image_set="", in_channels=1, input_size=(224, 224), cache=False, image_suffix=".jpg", mask_suffix=".png"):
"""
	åˆ†å‰²æ•°æ®é›†

	data_dir:str  æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„ï¼Œæ–‡ä»¶å¤¹è¦æ±‚æ˜¯
           |-dataset
                |- images
                    |-å›¾ç‰‡
                |- masks

    image_set:str "train.txt or val.txt or test.txt"
    in_channels:int  è¾“å…¥å›¾ç‰‡çš„é€šé“æ•°ï¼Œç›®å‰åªæ”¯æŒ1å’Œ3é€šé“
    input_size:tuple è¾“å…¥å›¾ç‰‡çš„HW
    preproc:albumentations.Compose å¯¹å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†
    cache:bool æ˜¯å¦å¯¹å›¾ç‰‡è¿›è¡Œå†…å­˜ç¼“å­˜
    images_suffix:str å¯æ¥å—çš„å›¾ç‰‡åç¼€
    mask_suffix:str
"""
```

**config.json**

```
"dataset": {
	"type": "SegDataset",
	"kwargs": {
		"data_dir": "/root/data/DAO/VOC2012_Seg_Aug",
		"image_set": "val.txt",
        "in_channels": 3,
        "input_size": [380, 380],
        "cache": false,
        "image_suffix":".jpg",
        "mask_suffix":".png"
	},
    "transforms": {
    	"kwargs": {
    		"Resize": {"height": 224, "width": 224, "p": 1},
    		"Normalize": {"mean": [0.398993, 0.431193, 0.452234], "std": [0.285205, 0.273126, 0.276610], "p": 1}
		}
	}
}
```

### SegDataloaderTrain

[source](../core/modules/dataloaders/SegDataloader.py)

**æ„é€ å‡½æ•°**

```
def SegDataloaderTrain(is_distributed=False, batch_size=None, num_workers=None, dataset=None, seed=0)
"""
is_distributed : bool æ˜¯å¦æ˜¯åˆ†å¸ƒå¼
batch_size : int batchsizeå¤§å°
num_workers : int è¯»å–æ•°æ®çº¿ç¨‹æ•°
dataset : DotMap æ•°æ®é›†é…ç½®
seed : int éšæœºç§å­
"""
```

**configs.json**

```
    "dataloader": {
        "type": "SegDataloaderTrain",
        "dataset": {
	        "type": "SegDataset",
            "kwargs": {
                    "data_dir": "/root/data/DAO/VOC2012_Seg_Aug",
                    "image_set": "val.txt",
                    "in_channels": 3,
                    "input_size": [380, 380],
                    "cache": false,
                    "image_suffix":".jpg",
                    "mask_suffix":".png"
	            },
            "transforms": {
                "kwargs": {
                    "Resize": {"height": 224, "width": 224, "p": 1},
                    "Normalize": {"mean": [0.398993, 0.431193, 0.452234], "std": [0.285205, 0.273126, 0.276610], "p": 1}
                }
            }
        },
        "kwargs": {
            "num_workers": 4,
            "batch_size": 32
        }
    }
```

### SegDataloaderEval

[source](../core/modules/dataloaders/SegDataloader.py)

**æ„é€ å‡½æ•°**

```
def SegDataloaderEval(is_distributed=False, batch_size=None, num_workers=None, dataset=None):
    """
    is_distributed : bool æ˜¯å¦æ˜¯åˆ†å¸ƒå¼
    batch_size : int batchsizeå¤§å°
    num_workers : int è¯»å–æ•°æ®çº¿ç¨‹æ•°
    dataset : DotMap æ•°æ®é›†é…ç½®
    """
```

**configs.json**

```
"dataloader": {
            "type": "SegDataloaderEval",
            "dataset": {
                "type": "SegDataset",
                "kwargs": {
                    "data_dir": "/root/data/DAO/VOC2012_Seg_Aug",
                    "image_set": "val.txt",
                    "in_channels": 3,
                    "input_size": [380, 380],
                    "cache": false,
                    "image_suffix":".jpg",
                    "mask_suffix":".png"
                },
                "transforms": {
                    "kwargs": {
                        "Resize": {"height": 224, "width": 224, "p": 1},
                        "Normalize": {"mean": [0.398993, 0.431193, 0.452234], "std": [0.285205, 0.273126, 0.276610], "p": 1}

                    }
                }
            },
            "kwargs": {
                "num_workers": 4,
                "batch_size": 32
            }
        }
```

## 4. losses

### CrossEntropyLoss

[source](../core/modules/losses/CrossEntropyLoss.py)

**æ„é€ å‡½æ•°**

```
def CrossEntropyLoss(weight=None, ignore_index=255, reduction='mean')

```

**configs.json**

```
"loss": {
        "type": "CrossEntropyLoss",
        "kwargs": {
            "ignore_index": 255,
            "weight": [
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
                1
            ],
            "reduction": "mean"
        }
    }
```

## 5. scheduler

### warm_cos_lr

[source](../core/modules/schedulers/warm_cos_lr.py)

**æ„é€ å‡½æ•°**

```
class warm_cos_lr(self, lr, iters_per_epoch, total_epochs, **kwargs):
        """
        Args:
            lr (float): learning rate.
            iters_per_peoch (int): number of iterations in one epoch.
            total_epochs (int): number of epochs in training.
            kwargs (dict):
                - warmup_epochs
                - warmup_lr_start (default 1e-6)
        """
```

**è°ƒç”¨æ–¹æ³•**

```
def update_lr(self, iters) æ›´æ–°lr
```

**configs**

```
"lr_scheduler": {
        "type": "warm_cos_lr",
        "kwargs": {
            "warmup_epochs": 5,
            "warmup_lr_start": 0
        }
    }
```

## 6. evaluators

### SegEvaluator

[source](../core/modules/evaluators/SegEvaluator.py)

**æ„é€ å‡½æ•°**

```
class SegEvaluator(is_distributed=False, dataloader=None, num_classes=None)
```

**è°ƒç”¨æ–¹æ³•**

```
evaluate(self, model, distributed=False, half=False, device=None)
```

**configs**

```
 "evaluator": {
        "type": "SegEvaluator",
        "dataloader": {
            "type": "SegDataloaderEval",
            "dataset": {
                "type": "SegDataset",
                "kwargs": {
                    "data_dir": "/root/data/DAO/VOC2012_Seg_Aug",
                    "image_set": "val.txt",
                    "in_channels": 3,
                    "input_size": [380, 380],
                    "cache": false,
                    "image_suffix":".jpg",
                    "mask_suffix":".png"
                },
                "transforms": {
                    "kwargs": {
                        "Resize": {"height": 224, "width": 224, "p": 1},
                        "Normalize": {"mean": [0.398993, 0.431193, 0.452234], "std": [0.285205, 0.273126, 0.276610], "p": 1}
                    }
                }
            },
            "kwargs": {
                "num_workers": 4,
                "batch_size": 32
            }
        }

    }
```



MVTecDataset

```
MVTecDataset(
    data_dir=None,
    preproc=None,
    image_set="",
    in_channels=1,
    input_size=(224, 224),
    cache=False,
    image_suffix=".png",
    mask_suffix=".png",
    **kwargs
)
```

å¼‚å¸¸æ£€æµ‹æ•°æ®é›†ï¼Œï¼ˆMVTecDatasetç±»å‹ï¼‰

**1. æ„é€ å‡½æ•°**

- data_dir:str  æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„ï¼Œæ–‡ä»¶å¤¹è¦æ±‚æ˜¯
      ğŸ“‚datasets
      â”— ğŸ“‚your_custom_dataset
      â”£ ğŸ“‚ ground_truth
      â”ƒ â”£ ğŸ“‚ defective_type_1
      â”ƒ â”— ğŸ“‚ defective_type_2
      â”£ ğŸ“‚ test
      â”ƒ â”£ ğŸ“‚ defective_type_1
      â”ƒ â”£ ğŸ“‚ defective_type_2
      â”ƒ â”— ğŸ“‚ good
      â”— ğŸ“‚ train
      â”ƒ â”— ğŸ“‚ good
- preproc:albumentations.Compose å¯¹å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†
- image_set:str "train.txt or val.txt or test.txt"
- in_channels:int  è¾“å…¥å›¾ç‰‡çš„é€šé“æ•°ï¼Œç›®å‰åªæ”¯æŒ1å’Œ3é€šé“
- input_size:tuple è¾“å…¥å›¾ç‰‡çš„HW
- cache:bool æ˜¯å¦å¯¹å›¾ç‰‡è¿›è¡Œå†…å­˜ç¼“å­˜
- image_suffix:str å¯æ¥å—çš„å›¾ç‰‡åç¼€
- mask_suffix:str å¯æ¥å—çš„å›¾ç‰‡åç¼€

**2.configs.json**



