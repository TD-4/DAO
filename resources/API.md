# API

## 1. models

### ğŸ•Backbones

[Pytorchè§†è§‰æ¨¡å‹åº“--timm](./timm_introduce.md) | [source](../core/modules/models/backbone/TIMM.py)

**æ„é€ å‡½æ•°**

```
def TIMM(backbone):
    # åˆ¤æ–­modelæ˜¯å¦åœ¨timmæ”¯æŒåˆ—è¡¨ä¸­
    if backbone.kwargs.model_name not in timm.list_models():
        logger.error("timm {} not supported {}".format(
            timm.__version__,
            backbone.kwargs.model_name))
        raise

    # åˆ¤æ–­modelæ˜¯å¦æœ‰pretrained
    if backbone.kwargs.pretrained and backbone.kwargs.model_name not in timm.list_models(pretrained=True):
        logger.error("{} hasn't pretrained weight, please set pretrained False".format(
            backbone.kwargs.model_name
        ))
        raise

    model = timm.create_model(**backbone.kwargs)
    return model

backbone: dict ä¸»å¹²ç½‘ç»œçš„é…ç½®å‚æ•°
```



**configs.json**

```
"backbone": {
            "kwargs": {
                "model_name":"efficientnet_b0",
                "pretrained": true,
                "checkpoint_path": "",
                "exportable": true,
                "in_chans": 1,
                "num_classes": 38
            }
        }
```

éœ€è¦åµŒå…¥å…¶ä»–ç½‘ç»œä¸­ä½¿ç”¨

### ğŸ¿Classifications

[source](../core/modules/models/cls/TIMMC.py)

**æ„é€ å‡½æ•°**

```
def TIMMC(backbone_kwargs):
    backbone = Registers.backbones.get("TIMM")(backbone_kwargs)
    return backbone
```

**configs.json**

```
"model": {
        "type": "TIMMC",
        "summary_size": [1,224,224],
        "backbone": {
            "kwargs": {
                "model_name":"efficientnet_b0",
                "pretrained": true,
                "checkpoint_path": "",
                "exportable": true,
                "in_chans": 1,
                "num_classes": 38
            }
        },
        "kwargs": {
        }
    }
```

### Unet

[source](../core/modules/models/seg/unet/model.py)

**æ„é€ å‡½æ•°**

```
class Unet( encoder,
            encoder_depth=5,
            encoder_channels=None,
            decoder_use_batchnorm: bool = True,
            decoder_channels: List[int] = (256, 128, 64, 32, 16),
            decoder_attention_type: Optional[str] = None,
            num_classes=2,
            activation: Optional[Union[str, callable]] = None,
            aux_params: Optional[dict] = None,
    )
"""
encoder: dict encoderçš„é…ç½®å­—å…¸
encoder_depth: encoderæ·±åº¦
encoder_channels: encoder çš„æ¯ä¸€å±‚channelæ•°
decoder_use_batchnorm: bool
decoder_channels: List[int] = (256, 128, 64, 32, 16),
decoder_attention_type: Optional[str] = None,
num_classes=2,
activation: Optional[Union[str, callable]] = None,
aux_params: Optional[dict] = None,
"""
```

**configs.json**

```
"model": {
        "type": "Unet",
        "summary_size": [3,224,224],
        "backbone": {
            "kwargs": {
                "model_name": "resnet18",
                "pretrained": true,
                "checkpoint_path": "",
                "exportable": true,
                "in_chans": 3,
                "features_only": true
            }
        },
        "kwargs": {
            "encoder_depth": 5,
            "encoder_channels": [3, 64, 64, 128, 256, 512],
            "decoder_channels": [256, 128, 64, 32, 16],
            "num_classes": 21
        }
    }
```

### ğŸ¦UNet++

[source](../core/modules/models/seg/unetplusplus/model.py) | [note](https://github.com/FelixFu520/README/blob/main/train/segmentation/unetpp.md)

**æ„é€ å‡½æ•°**

```
class UnetPlusPlus(SegmentationModel):
    def __init__(
        self,
        encoder,
        encoder_depth=5,
        encoder_channels=None,
        decoder_use_batchnorm: bool = True,
        decoder_channels: List[int] = (256, 128, 64, 32, 16),
        decoder_attention_type: Optional[str] = None,
        num_classes=2,
        activation: Optional[Union[str, callable]] = None,
        aux_params: Optional[dict] = None,
    ):
    
    encoderï¼šCNNç½‘ç»œï¼Œ å¯¹åº”configä¸­çš„backbone
    encoder_depth: CNNçš„æ·±åº¦ï¼Œå³encoder_channelsçš„é•¿åº¦
    encoder_channels: CNNä¸»å¹²ç½‘ç»œæå–ç‰¹å¾çš„é€šé“æ•°
    decoder_use_batchnorm: æ„å»ºdecoderç½‘ç»œæ—¶æ˜¯å¦ä½¿ç”¨BN
    decoder_channelsï¼šdecoderæ—¶ï¼Œè¾“å‡ºçš„é€šé“æ•°
    num_classes: ç±»åˆ«æ•°ï¼Œ VOCï¼ˆ20fg+1bg)æ‰€ä»¥VOCæ•°æ®é›†æ—¶num_classesè®¾ä¸º21
    activation: æ„å»ºdecoderæ—¶ï¼Œæ˜¯å¦ä½¿ç”¨ç‰¹å®šçš„æ¿€æ´»å‡½æ•°
    aux_params: æ„å»ºUNethical++çš„é¢å¤–å‚æ•°
    
```

UnetPlusPlusé€šè¿‡`__init__`å‡½æ•°åˆå§‹åŒ–ï¼Œé€šè¿‡`forward`å‡½æ•°è¿”å›æƒ³è¦çš„å€¼ã€‚

**config**

```
 "model": {
        "type": "UnetPlusPlus",
        "summary_size": [3,224,224],
        "backbone": {
            "kwargs": {
                "model_name": "tf_mobilenetv3_small_075",
                "pretrained": true,
                "checkpoint_path": "",
                "exportable": true,
                "in_chans": 3,
                "features_only": true
            }
        },
        "kwargs": {
            "encoder_depth": 5,
            "encoder_channels": [3, 16, 16, 24, 40, 432],
            "decoder_channels": [256, 128, 64, 32, 16],
            "num_classes": 21
        }
    }
```

![](models/imgs/20220111150339.jpg)

## 2. optims

### ğŸ”sgd_warmup_bias_bn_weight

[source](../core/modules/optims/sgd_warmup_bias_bn_weight.py)

**æ„é€ å‡½æ•°**

```
def sgd_warmup_bias_bn_weight(model=None,
                              lr=0.01,
                              weight_decay=1e-4,
                              momentum=0.9,
                              warmup_lr=0,
                              warmup_epoch=5
                              ):
    """
    model:torch.nn.Module æ­¤trainerçš„self.modelå±æ€§
    lr: float å¯¹äºæ•´ä¸ªï¼ˆå¤šæœºå¤šå¡ï¼‰batch sizeçš„å­¦ä¹ ç‡
    weight_decay:float torch.optim.SGD é»˜è®¤å‚æ•°
    momentum:float torch.optim.SGD é»˜è®¤å‚æ•°
    warmup_lr:float warmupæ—¶çš„å­¦ä¹ ç‡
    warmup_epoch:int warmupå‡ ä¸ªepoch
    """
```

**configs.json**

```
   "optimizer": {
        "type": "sgd_warmup_bias_bn_weight",
        "kwargs": {
            "lr": 0.01,
            "weight_decay": 1e-4,
            "momentum": 0.9,
            "warmup_lr": 0,
            "warmup_epoch": 5
        }
    }
```

## 3. datasets & dataloaders

### ğŸŸSegDataset

[source](../core/modules/dataloaders/datasets/SegDataset.py)

**æ„é€ å‡½æ•°**

```
Class SegDataset(data_dir=None, preproc=None, image_set="", in_channels=1, input_size=(224, 224), cache=False, image_suffix=".jpg", mask_suffix=".png"):
"""
	åˆ†å‰²æ•°æ®é›†

	data_dir:str  æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„ï¼Œæ–‡ä»¶å¤¹è¦æ±‚æ˜¯
           |-dataset
                |- images
                    |-å›¾ç‰‡
                |- masks

    image_set:str "train.txt or val.txt or test.txt"
    in_channels:int  è¾“å…¥å›¾ç‰‡çš„é€šé“æ•°ï¼Œç›®å‰åªæ”¯æŒ1å’Œ3é€šé“
    input_size:tuple è¾“å…¥å›¾ç‰‡çš„HW
    preproc:albumentations.Compose å¯¹å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†
    cache:bool æ˜¯å¦å¯¹å›¾ç‰‡è¿›è¡Œå†…å­˜ç¼“å­˜
    images_suffix:str å¯æ¥å—çš„å›¾ç‰‡åç¼€
    mask_suffix:str å¯æ¥å—çš„å›¾ç‰‡åç¼€
"""
```

**config.json**

```
"dataset": {
	"type": "SegDataset",
	"kwargs": {
		"data_dir": "/root/data/DAO/VOC2012_Seg_Aug",
		"image_set": "val.txt",
        "in_channels": 3,
        "input_size": [380, 380],
        "cache": false,
        "image_suffix":".jpg",
        "mask_suffix":".png"
	},
    "transforms": {
    	"kwargs": {
    		"Resize": {"height": 224, "width": 224, "p": 1},
    		"Normalize": {"mean": [0.398993, 0.431193, 0.452234], "std": [0.285205, 0.273126, 0.276610], "p": 1}
		}
	}
}
```

### ğŸ¥—SegDataloaderTrain

[source](../core/modules/dataloaders/SegDataloader.py)

**æ„é€ å‡½æ•°**

```
def SegDataloaderTrain(is_distributed=False, batch_size=None, num_workers=None, dataset=None, seed=0)
"""
is_distributed : bool æ˜¯å¦æ˜¯åˆ†å¸ƒå¼
batch_size : int batchsizeå¤§å°
num_workers : int è¯»å–æ•°æ®çº¿ç¨‹æ•°
dataset : DotMap æ•°æ®é›†é…ç½®
seed : int éšæœºç§å­
"""
```

è¿”å›ç±»å‹

```
train_loader = DataPrefetcherSeg(train_loader)
return train_loader, max_iter
```

**configs.json**

```
    "dataloader": {
        "type": "SegDataloaderTrain",
        "dataset": {
	        "type": "SegDataset",
            "kwargs": {
                    "data_dir": "/root/data/DAO/VOC2012_Seg_Aug",
                    "image_set": "val.txt",
                    "in_channels": 3,
                    "input_size": [380, 380],
                    "cache": false,
                    "image_suffix":".jpg",
                    "mask_suffix":".png"
	            },
            "transforms": {
                "kwargs": {
                    "Resize": {"height": 224, "width": 224, "p": 1},
                    "Normalize": {"mean": [0.398993, 0.431193, 0.452234], "std": [0.285205, 0.273126, 0.276610], "p": 1}
                }
            }
        },
        "kwargs": {
            "num_workers": 4,
            "batch_size": 32
        }
    }
```

### ğŸŒ­SegDataloaderEval

[source](../core/modules/dataloaders/SegDataloader.py)

**æ„é€ å‡½æ•°**

```
def SegDataloaderEval(is_distributed=False, batch_size=None, num_workers=None, dataset=None):
    """
    is_distributed : bool æ˜¯å¦æ˜¯åˆ†å¸ƒå¼
    batch_size : int batchsizeå¤§å°
    num_workers : int è¯»å–æ•°æ®çº¿ç¨‹æ•°
    dataset : DotMap æ•°æ®é›†é…ç½®
    """
```

è¿”å›ç±»å‹

```
val_loader = torch.utils.data.DataLoader(valdataset, **dataloader_kwargs)
return val_loader, len(val_loader)
```



**configs.json**

```
"dataloader": {
            "type": "SegDataloaderEval",
            "dataset": {
                "type": "SegDataset",
                "kwargs": {
                    "data_dir": "/root/data/DAO/VOC2012_Seg_Aug",
                    "image_set": "val.txt",
                    "in_channels": 3,
                    "input_size": [380, 380],
                    "cache": false,
                    "image_suffix":".jpg",
                    "mask_suffix":".png"
                },
                "transforms": {
                    "kwargs": {
                        "Resize": {"height": 224, "width": 224, "p": 1},
                        "Normalize": {"mean": [0.398993, 0.431193, 0.452234], "std": [0.285205, 0.273126, 0.276610], "p": 1}

                    }
                }
            },
            "kwargs": {
                "num_workers": 4,
                "batch_size": 32
            }
        }
```

### ğŸ³ClsDataset

[source](../core/modules/dataloaders/datasets/ClsDataset.py)

**æ„é€ å‡½æ•°**

```
class ClsDataset(Dataset):
    def __init__(self, data_dir=None, image_set="", in_channels=1,
                 input_size=(224, 224), preproc=None, cache=False,
                 separator=":", train_ratio=0.9, shuffle=True,
                 sample_range=(2000, 3000), images_suffix=None):
                 
   """
        åˆ†ç±»æ•°æ®é›†

        data_dir:str  æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„ï¼Œæ–‡ä»¶å¤¹è¦æ±‚æ˜¯
            |-dataset
                |- ç±»åˆ«1
                    |-å›¾ç‰‡
                |- ç±»åˆ«2

        image_set:str "train.txt or val.txt"
        in_channels:int  è¾“å…¥å›¾ç‰‡çš„é€šé“æ•°ï¼Œç›®å‰åªæ”¯æŒ1å’Œ3é€šé“
        input_size:tuple è¾“å…¥å›¾ç‰‡çš„HW
        preproc:albumentations.Compose å¯¹å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†
        cache:bool æ˜¯å¦å¯¹å›¾ç‰‡è¿›è¡Œå†…å­˜ç¼“å­˜
        separator:str labels.txt idä¸nameçš„åˆ†éš”ç¬¦
        train_ratio:float ç”Ÿæˆtrianlist.txtçš„æ¯”ä¾‹
        shuffle:bool ç”Ÿæˆtrain.txtæ—¶ï¼Œfolderä¸­çš„æ•°æ®æ˜¯å¦éšæœºæ‰“ä¹±
        sample_range:tuple æ¯ç±»å…è®¸çš„æœ€å¤šå›¾ç‰‡æ•°é‡çš„èŒƒå›´
        images_suffix:list[str] å¯æ¥å—çš„å›¾ç‰‡åç¼€
  """
```

**configs**

```
"dataset": {
                "type": "ClsDataset",
                "kwargs": {
                    "data_dir": "/root/data/DAO/screen",
                    "image_set": "val.txt",
                    "in_channels": 1,
                    "input_size": [224, 224],
                    "cache": false,
                    "train_ratio": 0.9,
                    "shuffle": true,
                    "sample_range": [2000, 3000],
                    "images_suffix": [".bmp"]
                },
                "transforms": {
                    "kwargs": {
                        "histogram": {"p": 1},
                        "Normalize": {"mean": 0, "std": 1, "p": 1}
                    }
            }
            },
```

### ğŸ›ClsDataloaderTrain

[source](../core/modules/dataloaders/ClsDataloader.py)

**æ„é€ å‡½æ•°**

```
def ClsDataloaderTrain(is_distributed=False, batch_size=None, num_workers=None, dataset=None, seed=0, **kwargs):
```

**configs**

```
 "dataloader": {
        "type": "ClsDataloaderTrain",
        "dataset": {
            "type": "ClsDataset",
            "kwargs": {
                "data_dir": "/root/data/DAO/screen",
                "image_set": "train.txt",
                "in_channels": 1,
                "input_size": [224, 224],
                "cache": false,
                "train_ratio": 0.9,
                "shuffle": true,
                "sample_range": [2000, 3000],
                "images_suffix": [".bmp"]
            },
            "transforms": {
                "kwargs": {
                    "histogram": {"p": 1},
                    "Normalize": {"mean": 0, "std": 1, "p": 1}
                }
            }
        },
        "kwargs": {
            "num_workers": 4,
            "batch_size": 256
        }
    },
```

### ğŸ¥©ClsDataloaderEval

[source](../core/modules/dataloaders/ClsDataloader.py)

**æ„é€ å‡½æ•°**

```
def ClsDataloaderEval(is_distributed=False, batch_size=None, num_workers=None, dataset=None, **kwargs):
```

**configs**

```
"dataloader": {
    "type": "ClsDataloaderEval",
    "dataset": {
        "type": "ClsDataset",
        "kwargs": {
            "data_dir": "/root/data/DAO/screen",
            "image_set": "val.txt",
            "in_channels": 1,
            "input_size": [224, 224],
            "cache": false,
            "train_ratio": 0.9,
            "shuffle": true,
            "sample_range": [2000, 3000],
            "images_suffix": [".bmp"]
        },
        "transforms": {
            "kwargs": {
                "histogram": {"p": 1},
                "Normalize": {"mean": 0, "std": 1, "p": 1}
            }
    }
    },
    "kwargs": {
        "num_workers": 4,
        "batch_size": 256
    }
},
```

### MVTecDataset

```
MVTecDataset(
    data_dir=None,
    preproc=None,
    image_set="",
    in_channels=1,
    input_size=(224, 224),
    cache=False,
    image_suffix=".png",
    mask_suffix=".png",
    **kwargs
)
```

å¼‚å¸¸æ£€æµ‹æ•°æ®é›†ï¼Œï¼ˆMVTecDatasetç±»å‹ï¼‰

**1. æ„é€ å‡½æ•°**

- data_dir:str  æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„ï¼Œæ–‡ä»¶å¤¹è¦æ±‚æ˜¯
      ğŸ“‚datasets
      â”— ğŸ“‚your_custom_dataset
      â”£ ğŸ“‚ ground_truth
      â”ƒ â”£ ğŸ“‚ defective_type_1
      â”ƒ â”— ğŸ“‚ defective_type_2
      â”£ ğŸ“‚ test
      â”ƒ â”£ ğŸ“‚ defective_type_1
      â”ƒ â”£ ğŸ“‚ defective_type_2
      â”ƒ â”— ğŸ“‚ good
      â”— ğŸ“‚ train
      â”ƒ â”— ğŸ“‚ good
- preproc:albumentations.Compose å¯¹å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†
- image_set:str "train.txt or val.txt or test.txt"
- in_channels:int  è¾“å…¥å›¾ç‰‡çš„é€šé“æ•°ï¼Œç›®å‰åªæ”¯æŒ1å’Œ3é€šé“
- input_size:tuple è¾“å…¥å›¾ç‰‡çš„HW
- cache:bool æ˜¯å¦å¯¹å›¾ç‰‡è¿›è¡Œå†…å­˜ç¼“å­˜
- image_suffix:str å¯æ¥å—çš„å›¾ç‰‡åç¼€
- mask_suffix:str å¯æ¥å—çš„å›¾ç‰‡åç¼€

**2.configs.json**

## 4. losses

### ğŸ—CrossEntropyLoss

[source](../core/modules/losses/CrossEntropyLoss.py)

**æ„é€ å‡½æ•°**

```
def CrossEntropyLoss(weight=None, ignore_index=255, reduction='mean')

```

**configs.json**

```
"loss": {
        "type": "CrossEntropyLoss",
        "kwargs": {
            "ignore_index": 255,
            "weight": [
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
                1
            ],
            "reduction": "mean"
        }
    }
```

## 5. scheduler

### ğŸ–warm_cos_lr

[source](../core/modules/schedulers/warm_cos_lr.py)

**æ„é€ å‡½æ•°**

```
class warm_cos_lr(self, lr, iters_per_epoch, total_epochs, **kwargs):
        """
        Args:
            lr (float): learning rate.
            iters_per_peoch (int): number of iterations in one epoch.
            total_epochs (int): number of epochs in training.
            kwargs (dict):
                - warmup_epochs
                - warmup_lr_start (default 1e-6)
        """
```

**è°ƒç”¨æ–¹æ³•**

```
def update_lr(self, iters) æ›´æ–°lr
```

**configs**

```
"lr_scheduler": {
        "type": "warm_cos_lr",
        "kwargs": {
            "warmup_epochs": 5,
            "warmup_lr_start": 0
        }
    }
```

## 6. evaluators

### ğŸ˜SegEvaluator

[source](../core/modules/evaluators/SegEvaluator.py)

**æ„é€ å‡½æ•°**

```
class SegEvaluator(is_distributed=False, dataloader=None, num_classes=None)
```

**è°ƒç”¨æ–¹æ³•**

```
evaluate(self, model, distributed=False, half=False, device=None)
```

**configs**

```
 "evaluator": {
        "type": "SegEvaluator",
        "dataloader": {
            "type": "SegDataloaderEval",
            "dataset": {
                "type": "SegDataset",
                "kwargs": {
                    "data_dir": "/root/data/DAO/VOC2012_Seg_Aug",
                    "image_set": "val.txt",
                    "in_channels": 3,
                    "input_size": [380, 380],
                    "cache": false,
                    "image_suffix":".jpg",
                    "mask_suffix":".png"
                },
                "transforms": {
                    "kwargs": {
                        "Resize": {"height": 224, "width": 224, "p": 1},
                        "Normalize": {"mean": [0.398993, 0.431193, 0.452234], "std": [0.285205, 0.273126, 0.276610], "p": 1}
                    }
                }
            },
            "kwargs": {
                "num_workers": 4,
                "batch_size": 32
            }
        }

    }
```

### ğŸ ClsEvaluator

[source](../core/modules/evaluators/ClsEvaluator.py)

**æ„é€ å‡½æ•°**

```
class ClsEvaluator:
    def __init__(self, is_distributed=False, dataloader=None, num_classes=None, is_industry=False, industry=None):
```

**configs**

```
"evaluator": {
        "type": "ClsEvaluator",
        "dataloader": {
            "type": "ClsDataloaderEval",
            "dataset": {
                "type": "ClsDataset",
                "kwargs": {
                    "data_dir": "/root/data/DAO/screen",
                    "image_set": "val.txt",
                    "in_channels": 1,
                    "input_size": [224, 224],
                    "cache": false,
                    "train_ratio": 0.9,
                    "shuffle": true,
                    "sample_range": [2000, 3000],
                    "images_suffix": [".bmp"]
                },
                "transforms": {
                    "kwargs": {
                        "histogram": {"p": 1},
                        "Normalize": {"mean": 0, "std": 1, "p": 1}
                    }
            }
            },
            "kwargs": {
                "num_workers": 4,
                "batch_size": 256
            }
        },
        "kwargs": {
            "num_classes": 38,
            "is_industry": false
        }

    }
```

## 7. trainer

