# CFLOW-AD

- [CFLOW-AD: Real-Time Unsupervised Anomaly Detection with Localization via Conditional Normalizing Flows](https://arxiv.org/pdf/2107.12571v1.pdf)

- https://github.com/janosh/awesome-normalizing-flows


---

## 1. PaperğŸ“•

#### **Abstract** 

Unsupervised anomaly detection with localization has many practical applications when labeling is infeasible and, moreover, when anomaly examples are completely missing in the train data. <u>ï¼ˆæ— ç›‘ç£å¼‚å¸¸æ£€æµ‹å’Œå®šä½æœ‰å¾ˆå¤šå®ç”¨çš„åº”ç”¨ï¼Œå½“åœ¨æ ‡è®°æ–¹æ³•ä¸å¯è¡Œä»¥åŠå¼‚å¸¸å®ä¾‹åœ¨è®­ç»ƒæ•°æ®ä¸­å®Œå…¨ç¼ºå¤±çš„æƒ…å†µä¸‹ï¼‰</u>ã€‚While recently proposed models for such data setup achieve high accuracy metrics, their complexity is a limiting factor for real-time processing. <u>ï¼ˆè™½ç„¶æœ€è¿‘ä¸ºæ­¤ç±»é—®é¢˜æå‡ºçš„æ¨¡å‹å®ç°äº†é«˜ç²¾åº¦åº¦é‡ï¼Œä½†å®ƒä»¬çš„å¤æ‚æ€§æ˜¯å®æ—¶å¤„ç†çš„ä¸€ä¸ªé™åˆ¶å› ç´ ï¼‰</u>ã€‚In this paper, we propose a real-time model and analytically derive its relationship to prior methods.<u>ï¼ˆåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå®æ—¶æ¨¡å‹ï¼Œå¹¶åˆ†ææ¨å¯¼å‡ºå®ƒä¸ç°æœ‰æ–¹æ³•çš„å…³ç³»ï¼‰</u>ã€‚ Our CFLOW-AD model is based on a conditional normalizing flow framework adopted for anomaly detection with localization. In particular, CFLOW-AD consists of a discriminatively pretrained encoder followed by a multi-scale generative decoders where the latter explicitly estimate likelihood of the encoded features. <u>ï¼ˆæˆ‘ä»¬çš„CFLOW-ADæ¨¡å‹æ˜¯**åŸºäºä¸€ä¸ªæœ‰æ¡ä»¶çš„å½’ä¸€åŒ–æµç¨‹æ¡†æ¶**ï¼Œç”¨äºå¼‚å¸¸æ£€æµ‹å’Œå®šä½ã€‚ç‰¹åˆ«åœ°ï¼ŒCFLOW-ADç”±ä¸€ä¸ªæœ‰åŒºåˆ«çš„é¢„å…ˆè®­ç»ƒçš„**ç¼–ç å™¨**å’Œä¸€ä¸ªå¤šå°ºåº¦ç”Ÿæˆ**è§£ç å™¨**ç»„æˆï¼Œåè€…æ˜¾å¼åœ°ä¼°è®¡ç¼–ç ç‰¹å¾çš„å¯èƒ½æ€§ï¼‰</u>ã€‚Our approach results in a computationally and memory-efficient model: CFLOW-AD is faster and smaller by a factor of 10Ã— than prior state-of-the-art with the same input setting. Our experiments on the MVTec dataset show that CFLOW-AD outperforms previous methods by 0.36% AUROC in detection task, by 1.12% AUROC and 2.5% AUPRO in localization task, respectively. We open-source our code with fully reproducible experiments1ï¼ˆ<u>æˆ‘ä»¬çš„æ–¹æ³•å¾—åˆ°äº†ä¸€ä¸ªè®¡ç®—å’Œå†…å­˜æ•ˆç‡é«˜çš„æ¨¡å‹:CFLOW-ADçš„é€Ÿåº¦æ›´å¿«ï¼Œä½“ç§¯ä¹Ÿæ›´å°ï¼Œåœ¨ç›¸åŒçš„è¾“å…¥è®¾ç½®ä¸‹ï¼Œå®ƒæ¯”ä¹‹å‰çš„å…ˆè¿›æŠ€æœ¯è¦å°10å€ã€‚åœ¨MVTecæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒCFLOW-ADåœ¨æ£€æµ‹ä»»åŠ¡ä¸Šçš„AUROCåˆ†åˆ«æ¯”ç°æœ‰æ–¹æ³•æé«˜äº†0.36%ï¼Œåœ¨å®šä½ä»»åŠ¡ä¸Šçš„AUROCåˆ†åˆ«æé«˜äº†1.12%å’Œ2.5%ã€‚æˆ‘ä»¬ç”¨å®Œå…¨å¯é‡å¤çš„å®éªŒæ¥å¼€æ”¾æˆ‘ä»¬çš„ä»£ç </u>ï¼‰ã€‚



#### 1. Introduction 

Anomaly detection with localization (AD) is a growing area of research in computer vision with many practical applications e.g. industrial inspection [4], road traffic monitoring [20], medical diagnostics [44] etc. ï¼ˆ<u>åŸºäºå±€éƒ¨åŒ–çš„å¼‚å¸¸æ£€æµ‹æ˜¯ä¸€ç§æ–°å…´çš„æ£€æµ‹æ–¹æ³•è®¡ç®—æœºè§†è§‰çš„ç ”ç©¶é¢†åŸŸï¼Œå…·æœ‰è®¸å¤šå®é™…åº”ç”¨ï¼Œå¦‚å·¥ä¸šæ£€æµ‹[4]ï¼Œé“è·¯äº¤é€šç›‘æµ‹[20]ï¼ŒåŒ»ç–—è¯Šæ–­[44]ç­‰</u>ï¼‰ã€‚However, the common supervised AD [32] is not viable in practical applications due to several reasons. First, it requires labeled data which is costly to obtain. Second, anomalies are usually rare long-tail examples and have low probability to be acquired by sensors. Lastly, consistent labeling of anomalies is subjective and requires extensive domain expertise as illustrated in Figure 1 with industrial cable defects. ï¼ˆ<u>ä½†æ˜¯ï¼Œç”±äºå‡ ä¸ªåŸå› ï¼Œå¸¸è§çš„æœ‰ç›‘ç£çš„AD[32]åœ¨å®é™…åº”ç”¨ä¸­æ˜¯ä¸å¯è¡Œçš„ã€‚é¦–å…ˆï¼Œå®ƒéœ€è¦æœ‰æ ‡ç­¾çš„æ•°æ®è¿™æ˜¯æ˜‚è´µçš„è·å¾—ã€‚ç¬¬äºŒï¼Œå¼‚å¸¸ç°è±¡é€šå¸¸éƒ½å­˜åœ¨ç½•è§çš„é•¿å°¾ä¾‹å­ï¼Œè¢«ä¼ æ„Ÿå™¨æ•è·çš„æ¦‚ç‡å¾ˆä½ã€‚æœ€åï¼Œå¯¹å¼‚å¸¸ç°è±¡è¿›è¡Œä¸€è‡´çš„æ ‡è®°æ˜¯ä¸»è§‚çš„ï¼Œéœ€è¦å¹¿æ³›çš„é¢†åŸŸä¸“ä¸šçŸ¥è¯†ï¼Œå¦‚å›¾1æ‰€ç¤ºï¼Œå·¥ä¸šç”µç¼†ç¼ºé™·</u>ï¼‰ã€‚



With these limitations of the supervised AD, a more appealing approach is to collect only unlabeled anomaly-free images for train dataset Dtrain as in Figure 1 (top row). ï¼ˆ<u>æœ‰äº†ç›‘ç£ADçš„è¿™äº›é™åˆ¶ï¼Œä¸€ç§æ›´æœ‰å¸å¼•åŠ›çš„æ–¹æ³•æ˜¯åªæ”¶é›†æ— æ ‡è®°çš„å¼‚å¸¸å¦‚å›¾1æ‰€ç¤º(ç¬¬ä¸€è¡Œ)</u>ï¼‰ã€‚Then, any deviation from anomaly-free images is classified as an anomaly. Such data setup with low rate of anomalies is generally considered to be unsupervised [4]. ï¼ˆç„¶åï¼Œå¯¹ä»»ä½•ä¸æ— å¼‚å¸¸å›¾åƒçš„åå·®è¿›è¡Œåˆ†ç±»ä½œä¸ºä¸€ä¸ªå¼‚å¸¸ã€‚è¿™æ ·çš„æ•°æ®è®¾ç½®å¼‚å¸¸ç‡ä½é€šå¸¸è¢«è®¤ä¸ºæ˜¯æ— ç›‘ç£[4]ï¼‰ã€‚Hence, the AD task can be reformulated as a task of out-of-distribution detection (OOD) with the AD objective. ï¼ˆå› æ­¤,ADä»»åŠ¡å¯ä»¥è¢«é‡æ–°å®šä¹‰ä¸ºéåˆ†å¸ƒä»»åŠ¡æ£€æµ‹(OOD)ä¸ADç›®æ ‡ï¼‰ã€‚



![image-20220104152821143](imgs/image-20220104152821143.png)

Figure 1. An example of the proposed out-of-distribution (OOD) detector for anomaly localization trained on anomaly-free Dtrain (top row). å›¾1æ‰€ç¤ºã€‚å»ºè®®çš„éåˆ†é…(OOD)ç¤ºä¾‹åŸºäºæ— å¼‚å¸¸Dtrainè®­ç»ƒçš„å¼‚å¸¸å®šä½æ£€æµ‹å™¨(ä¸Šé¢ä¸€è¡Œ)ã€‚ Sliced cable images are from the MVTec dataset [4], where the bottom row illustrates Dtest ground truth masks for anomalies (red) and the middle row shows examples of anomalyfree patches (green). The OOD detector learns the distribution of anomaly-free patches x with pX(x) density and transforms it into a Gaussian distribution with pZ (z) density. Threshold Ï„ separates in-distribution patches from the OOD patches with pZËœ(z) density .åˆ‡ç‰‡ç”µç¼†å›¾åƒæ¥è‡ªMVTecæ•°æ®é›†[4]ï¼Œæœ€ä¸‹é¢ä¸€æ’æ˜¯Dtest ground truth maskså…·å¼‚å¸¸(çº¢è‰²)å’Œä¸­é—´ä¸€è¡Œæ˜¾ç¤ºæ— å¼‚å¸¸æ–‘å—(ç»¿è‰²)çš„ä¾‹å­ã€‚OODæ£€æµ‹å™¨å­¦ä¹ çš„åˆ†å¸ƒå°†pX(x)å¯†åº¦çš„æ— å¼‚å¸¸patch xè½¬æ¢ä¸ºpZ (z)å¯†åº¦çš„é«˜æ–¯åˆ†å¸ƒã€‚é˜ˆå€¼Ï„åˆ†ç¦»åŸºäºpZ ~ (z)å¯†åº¦çš„OOD patchçš„å†…åˆ†å¸ƒpatch



While OOD for low-dimensional industrial sensors (e.g.power-line or acoustic) can be accomplished using a common k-nearest-neighbor or more advanced clustering methods [10], it is less trivial for high-resolution images. è€Œç”¨äºä½ç»´å·¥ä¸šä¼ æ„Ÿå™¨çš„OOD(å¦‚ç”µåŠ›çº¿æˆ–å£°å­¦)å¯ä»¥ä½¿ç”¨æ™®é€šçš„k-æœ€è¿‘é‚»æˆ–æ›´é«˜çº§çš„èšç±»æ–¹æ³•[10]æ¥å®Œæˆï¼Œå®ƒå¯¹äºé«˜åˆ†è¾¨ç‡çš„å›¾åƒä¸æ˜¯é‚£ä¹ˆç®€å•ã€‚ Recently, convolutional neural networks (CNNs) have gained bpopularity in extracting semantic information from images into downsampled feature maps [4]. xè¿‘å¹´æ¥ï¼Œå·ç§¯ç¥ç»ç½‘ç»œå¾—åˆ°äº†å¹¿æ³›çš„åº”ç”¨æµè¡Œäºä»å›¾åƒä¸­æå–è¯­ä¹‰ä¿¡æ¯ä¸‹é‡‡æ ·ç‰¹å¾æ˜ å°„[4]ã€‚ Though feature extraction using CNNs has relatively low complexity, the postprocessing of feature maps is far from real-time processing in the state-of-the-art unsupervised AD methods [8].è™½ç„¶åˆ©ç”¨cnnè¿›è¡Œç‰¹å¾æå–çš„å¤æ‚åº¦ç›¸å¯¹è¾ƒä½ï¼Œä½†ç‰¹å¾å›¾çš„åå¤„ç†ä¸å®æ—¶å¤„ç†ç›¸å»ç”šè¿œåœ¨æœ€å…ˆè¿›çš„æ— ç›‘ç£ADæ–¹æ³•ä¸­[8]ã€‚



To address this complexity drawback, we propose a CFLOW-AD model that is based on conditional normalizing flows. ä¸ºäº†è§£å†³è¿™ä¸ªå¤æ‚çš„ç¼ºç‚¹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŸºäºæ¡ä»¶å½’ä¸€åŒ–æµç¨‹çš„CFLOW-ADæ¨¡å‹ã€‚ CFLOW-AD is agnostic to feature map spatial dimensions similar to CNNs, which leads to a higher accuracy metrics as well as a lower computational and memory requirements.CFLOW-ADå¯¹äºç‰¹å¾æ˜ å°„ç©ºé—´æ˜¯ä¸å¯çŸ¥çš„ç±»ä¼¼cnnçš„å°ºå¯¸ï¼Œè¿™å¯¼è‡´äº†æ›´é«˜çš„ç²¾åº¦æŒ‡æ ‡ï¼Œä»¥åŠè¾ƒä½çš„è®¡ç®—å’Œå†…å­˜è¦æ±‚ã€‚  We present the main idea behind our approach in a toy OOD detector example in Figure 1.æˆ‘ä»¬åœ¨å›¾1ä¸­çš„ä¸€ä¸ªç©å…·OODæ£€æµ‹å™¨ç¤ºä¾‹ä¸­å±•ç¤ºäº†è¿™ç§æ–¹æ³•èƒŒåçš„ä¸»è¦æ€æƒ³ã€‚  A distribution of the anomaly-free image patches x with probability density function pX(x) is learned by the AD model. é€šè¿‡ADæ¨¡å‹å­¦ä¹ æ— å¼‚å¸¸å›¾åƒå—xçš„æ¦‚ç‡å¯†åº¦å‡½æ•°ä¸ºpX(x)çš„åˆ†å¸ƒã€‚Our translation-equivariant model is trained to transform the original distribution with pX(x) density into a Gaussian distribution with pZ(z) density.æˆ‘ä»¬çš„å¹³ç§»ç­‰å˜æ¨¡å‹è¢«è®­ç»ƒæˆå˜æ¢åŸå¯†åº¦ä¸ºpX(x)çš„åˆ†å¸ƒå˜ä¸ºå¯†åº¦ä¸ºpZ(z)çš„é«˜æ–¯åˆ†å¸ƒã€‚  Finally, this model separates in-distribution patches z with pZ(z) from the outof-distribution patches with pZËœ(z) using a threshold Ï„ computed as the Euclidean distance from the distribution mean. æœ€å,è¿™ä¸ªæ¨¡å‹ä½¿ç”¨é˜ˆå€¼Ï„è®¡ç®—ä¸ºä¸åˆ†å¸ƒå‡å€¼çš„æ¬§æ°è·ç¦»ï¼Œå°†å…·æœ‰pZ(z)çš„åˆ†å¸ƒå†…patch zä¸å…·æœ‰pZ(z)çš„åˆ†å¸ƒå¤–patchåˆ†ç¦»ã€‚



#### 2. Related work

 We review models2 that employ the data setup from Figure 1 and provide experimental results for popular MVTec dataset [4] with factory defects or Shanghai Tech Campus (STC) dataset [22] with surveillance camera videos. æˆ‘ä»¬å›é¡¾models2å®ƒä»¬é‡‡ç”¨äº†å›¾1ä¸­çš„æ•°æ®è®¾ç½®ï¼Œå¹¶ä¸ºæµè¡Œçš„MVTecæä¾›äº†å®éªŒç»“æœæ•°æ®é›†[4]å·¥å‚ç¼ºé™·æˆ–ä¸Šæµ·æŠ€æœ¯å›­åŒº(STC)æ•°æ®é›†[22]ä¸ç›‘æ§æ‘„åƒæœºè§†é¢‘ã€‚We highlight the research related to a more challenging task of pixel-level anomaly localization (segmentation) rather than a more simple image-level anomaly detection.æˆ‘ä»¬çªå‡ºç ”ç©¶çš„ä¸€ä¸ªæ›´æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡åƒç´ çº§å¼‚å¸¸å®šä½(åˆ†å‰²)è€Œä¸æ˜¯ä¸€ç§æ›´ç®€å•çš„å›¾åƒçº§å¼‚å¸¸æ£€æµ‹ã€‚



Napoletano et al. [25] propose to use CNN feature extractors followed by a principal component analysis and kmean clustering for AD. Their feature extractor is a ResNet18 [13] pretrained on a large-scale ImageNet dataset [16]. Similarly, SPADE [7] employs a Wide-ResNet-50 [43] with multi-scale pyramid pooling that is followed by a k-nearestneighbor clustering. Unfortunately, clustering is slow at test-time with high-dimensional data. Thus, parallel convolutional methods are preferred in real-time systems.

Napoletano et al.[25]æå‡ºä½¿ç”¨CNNç‰¹å¾æå–å™¨ï¼Œç„¶åè¿›è¡Œä¸»æˆåˆ†åˆ†æå’Œkmeanèšç±»æ¥è¿›è¡ŒADã€‚ä»–ä»¬çš„ç‰¹å¾æå–å™¨æ˜¯åœ¨å¤§è§„æ¨¡ImageNetæ•°æ®é›†[16]ä¸Šé¢„å…ˆè®­ç»ƒçš„ResNet18[13]ã€‚ç±»ä¼¼åœ°ï¼ŒSPADE[7]ä½¿ç”¨äº†å®½resnet -50 [43]å¤šå°ºåº¦é‡‘å­—å¡”æ± ï¼Œç„¶åæ˜¯kè¿‘é‚»èšç±»ã€‚ä¸å¹¸çš„æ˜¯ï¼Œé›†ç¾¤æ˜¯ç¼“æ…¢çš„é«˜ç»´æ•°æ®çš„æµ‹è¯•æ—¶é—´ã€‚å› æ­¤ï¼Œå¹¶è¡Œå·ç§¯æ–¹æ³•åœ¨å®æ—¶ç³»ç»Ÿä¸­æ˜¯é¦–é€‰ã€‚



Numerous methods are based on a natural idea of generative modeling. Unlike models with the discriminatively pretrained feature extractors [25, 7], generative models learn distribution of anomaly-free data and, therefore, are able to estimate a proxy metrics for anomaly scores even for the unseen images with anomalies. Recent models employ generative adversarial networks (GANs) [35, 36] and variational autoencoders (VAEs) [3, 38].

è®¸å¤šæ–¹æ³•éƒ½åŸºäºç”Ÿæˆå»ºæ¨¡çš„è‡ªç„¶æ€æƒ³ã€‚ä¸åƒæœ‰åŒºåˆ«åœ°é¢„å…ˆè®­ç»ƒçš„ç‰¹å¾æå–å™¨çš„æ¨¡å‹[25,7]ï¼Œç”Ÿæˆæ¨¡å‹äº†è§£æ— å¼‚å¸¸æ•°æ®çš„åˆ†å¸ƒï¼Œå› æ­¤ï¼Œæ˜¯èƒ½å¤Ÿä¼°è®¡ä¸€ä¸ªä»£ç†æŒ‡æ ‡çš„å¼‚å¸¸åˆ†æ•°ç”šè‡³çœ‹ä¸è§çš„å¼‚å¸¸å›¾åƒã€‚æœ€è¿‘çš„æ¨¡å‹é‡‡ç”¨ç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œ(GANs)[35,36]å’Œå˜åˆ†è‡ªåŠ¨ç¼–ç å™¨(VAEs)[3,38]ã€‚



A fully-generative models [35, 36, 3, 38] are directly applied to images in order to estimate pixel-level probability density and compute per-pixel reconstruction errors as anomaly scores proxies.å°†å®Œå…¨ç”Ÿæˆæ¨¡å‹[35,36,3,38]ç›´æ¥åº”ç”¨äºå›¾åƒï¼Œä»¥ä¼°è®¡åƒç´ çº§æ¦‚ç‡å¯†åº¦ï¼Œå¹¶è®¡ç®—é€åƒç´ é‡å»ºè¯¯å·®ä½œä¸ºå¼‚å¸¸è¯„åˆ†ä»£ç†ã€‚ These fully-generative models are unable to estimate the exact data likelihoods [6, 24] and do not perform better than the traditional methods [25, 7] according to MVTec survey in [4]. è¿™äº›å®Œå…¨ç”Ÿæˆçš„æ¨¡å‹æ˜¯æ— æ³•ä¼°è®¡å‡†ç¡®çš„æ•°æ®å¯èƒ½æ€§[6,24]å’Œåšæ ¹æ®[4]ä¸­MVTecçš„è°ƒæŸ¥ï¼Œå¹¶ä¸æ¯”ä¼ ç»Ÿæ–¹æ³•æ›´å¥½[25,7]ã€‚ Recent works [34, 15] show that these models tend to capture only low-level correlations instead of relevant semantic information. è¿‘æœŸä½œå“[34,15]è¡¨æ˜è¿™äº›æ¨¡å‹å¾€å¾€åªæ•è·ä½çº§çš„ç›¸å…³æ€§ï¼Œè€Œä¸æ˜¯ç›¸å…³çš„è¯­ä¹‰ä¿¡æ¯ã€‚ To overcome the latter drawback, a hybrid DFR model [37] uses a pretrained feature extractor with multi-scale pyramid pooling followed by a convolutional autoencoder (CAE). However, DFR model is unable to estimate the exact likelihoods. ä¸ºäº†å…‹æœåä¸€ä¸ªç¼ºç‚¹ï¼Œæ··åˆDFRæ¨¡å‹[37]ä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„å¤šå°ºåº¦é‡‘å­—å¡”æ± ç‰¹å¾æå–å™¨ï¼Œç„¶åæ˜¯å·ç§¯è‡ªåŠ¨ç¼–ç å™¨(CAE)ã€‚ç„¶è€Œï¼ŒDFRæ¨¡å‹æ— æ³•ä¼°è®¡ç¡®åˆ‡çš„å¯èƒ½æ€§ã€‚



Another line of research proposes to employ a studentteacher type of framework [5, 33, 41]. Teacher is a pretrained feature extractor and student is trained to estimate a scoring function for AD. Unfortunately, such frameworks underperform compared to state-of-the-art models

å¦ä¸€é¡¹ç ”ç©¶å»ºè®®é‡‡ç”¨å­¦ç”Ÿæ•™å¸ˆç±»å‹çš„æ¡†æ¶[5,33,41]ã€‚æ•™å¸ˆæ˜¯ç»è¿‡è®­ç»ƒçš„ç‰¹å¾æå–å™¨ï¼Œè€Œå­¦ç”Ÿåˆ™æ˜¯ç»è¿‡è®­ç»ƒçš„ä¼°è®¡å™¨ADè¯„åˆ†åŠŸèƒ½ã€‚ä¸å¹¸çš„æ˜¯,è¿™ç§æ¡†æ¶ä¸æœ€å…ˆè¿›çš„æ¨¡å‹ç›¸æ¯”è¡¨ç°ä¸ä½³ã€‚



Patch SVDD [42] and CutPaste [19] introduce a selfsupervised pretraining scheme for AD. Moreover, Patch SVDD proposes a novel method to combine multi-scale scoring masks to a final anomaly map. è¡¥ä¸SVDD[42]å’ŒCutPaste[19]ä¸ºADå¼•å…¥äº†ä¸€ç§è‡ªç›‘ç£çš„é¢„è®­ç»ƒæ–¹æ¡ˆã€‚æ­¤å¤–,è¡¥ä¸SVDDæå‡ºäº†ä¸€ç§æ–°çš„å¤šå°ºåº¦ç»“åˆçš„æ–¹æ³•ä¸ºå¼‚å¸¸åœ°å›¾æ‰“åˆ†ã€‚Unlike the nearestneighbor search in [42], CutPaste estimates anomaly scores using an efficient Gaussian density estimator. ä¸[42]ä¸­çš„æœ€è¿‘é‚»æœç´¢ä¸åŒï¼ŒCutPasteä¼°è®¡å¼‚å¸¸åˆ†æ•°ä½¿ç”¨æœ‰æ•ˆçš„é«˜æ–¯å¯†åº¦ä¼°è®¡ã€‚ While the self-supervised pretraining can be helpful in uncommon data domains, Schirrmeister et al. [34] argue that large natural-image datasets such as ImageNet can be a more representative for pretraining compared to a small applicationspecific datasets e.g. industrial MVTec [4].è€Œè‡ªæˆ‘ç›‘ç£çš„é¢„è®­ç»ƒåœ¨ä¸å¸¸è§çš„æƒ…å†µä¸‹æ˜¯æœ‰ç”¨çš„æ•°æ®åŸŸï¼ŒSchirrmeisterç­‰äººã€‚[34]è®¤ä¸ºå¤§è‡ªç„¶å›¾åƒæ•°æ®é›†(å¦‚ImageNet)æ¯”å°å‹åº”ç”¨ç‰¹å®šæ•°æ®é›†(å¦‚å·¥ä¸šMVTec[4])æ›´èƒ½ä»£è¡¨é¢„è®­ç»ƒã€‚



The state-of-the-art PaDiM [8] proposes surprisingly simple yet effective approach for anomaly localization. æœ€å…ˆè¿›çš„padm[8]çš„æè®®ä»¤äººæƒŠè®¶ä¸€ç§ç®€å•æœ‰æ•ˆçš„å¼‚å¸¸å®šä½æ–¹æ³•ã€‚ Similarly to [37, 7, 42], this approach relies on ImageNet pretrained feature extractor with multi-scale pyramid pooling. ä¸[37,7,42]ç±»ä¼¼ï¼Œè¯¥æ–¹æ³•ä¾èµ–äºimagenet pretrainingçš„å¤šå°ºåº¦é‡‘å­—å¡”æ± ç‰¹å¾æå–å™¨ã€‚ However, instead of slow test-time clustering in [7] or nearest-neighbor search in [42], PaDiM uses a wellknown Mahalanobis distance metric [23] as an anomaly score.ä½†æ˜¯ï¼Œä¸åœ¨[7]ä¸­ç¼“æ…¢çš„æµ‹è¯•æ—¶é›†ç¾¤ä¸åŒæˆ–åœ¨[42]ä¸­è¿›è¡Œæœ€è¿‘é‚»æœç´¢æ—¶ï¼Œpadimä½¿ç”¨è‘—åçš„é©¬æ°è·ç¦»åº¦é‡[23]ä½œä¸ºå¼‚å¸¸å¾—åˆ†ã€‚  The metric parameters are estimated for each feature vector from the pooled feature maps. ä»é›†åˆçš„ç‰¹å¾æ˜ å°„ä¸­ä¼°è®¡æ¯ä¸ªç‰¹å¾å‘é‡çš„åº¦é‡å‚æ•°ã€‚PaDiM has been inspired by Rippel et al. [29] who firstly advocated to use this measure for anomaly detection without localization.PaDiMä¸€ç›´å—Rippelç­‰äºº[29]çš„å¯å‘ï¼Œä»–ä»¬é¦–å…ˆå€¡å¯¼ä½¿ç”¨è¿™ç§æ–¹æ³•ç”¨äºä¸å®šä½çš„å¼‚å¸¸æ£€æµ‹ã€‚



DifferNet [30] uses a promising class of generative models called normalizing flows (NFLOWs) [9] for image-level AD. DifferNet[30]ä½¿ç”¨äº†ä¸€ä¸ªå¾ˆæœ‰å‰é€”çš„ç”Ÿæˆæ¨¡å‹ç±»ï¼Œç§°ä¸ºæ ‡å‡†åŒ–æµ(NFLOWs)[9]ï¼Œç”¨äºå›¾åƒçº§ã€‚ The main advantage of NFLOW models is ability to estimate the exact likelihoods for OOD compared to other generative models [35, 36, 3, 38, 37].NFLOWæ¨¡å‹çš„ä¸»è¦ä¼˜ç‚¹æ˜¯èƒ½å¤Ÿä¸å…¶ä»–ç–¾ç—…ç›¸æ¯”ï¼Œä¼°è®¡OODçš„ç¡®åˆ‡å¯èƒ½æ€§ç”Ÿæˆæ¨¡å‹[35,36,3,38,37]ã€‚  In this paper, we extend DifferNet approach to pixel-level anomaly localization task using our CFLOW-AD model. åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†DifferNetæ–¹æ³•æ‰©å±•åˆ°åƒç´ çº§å¼‚å¸¸å®šä½ä½¿ç”¨æˆ‘ä»¬çš„CFLOW-ADæ¨¡å‹ã€‚ In contrast to RealNVP [9] architecture with global average pooling in [30], we propose to use conditional normalizing flows [2] to make CFLOW-AD suitable for low-complexity processing of multi-scale feature maps for localization task. We develop our CFLOW-AD with the following contributions:ä¸RealNVP[9]æ¶æ„åœ¨[30]ä¸­ä½¿ç”¨å…¨å±€å¹³å‡æ± ç›¸æ¯”ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨æ¡ä»¶å½’ä¸€åŒ–æµç¨‹[2]åˆ°ä½¿CFLOW-ADé€‚ç”¨äºä½å¤æ‚åº¦çš„å¤„ç†ç”¨äºå®šä½ä»»åŠ¡çš„å¤šå°ºåº¦ç‰¹å¾å›¾ã€‚æˆ‘ä»¬å¼€å‘CFLOW-ADçš„è´¡çŒ®å¦‚ä¸‹:

- Our theoretical analysis shows why multivariate Gaussian assumption is a justified prior in previous models and why a more general NFLOW framework objective converges to similar results with the less compute.æˆ‘ä»¬çš„ç†è®ºåˆ†æè¡¨æ˜ï¼Œä¸ºä»€ä¹ˆå¤šå…ƒé«˜æ–¯å‡è®¾æ˜¯ä¸€ä¸ªåˆç†çš„å…ˆéªŒåœ¨ä»¥å‰çš„æ¨¡å‹ä»¥åŠä¸ºä»€ä¹ˆä½¿ç”¨æ›´é€šç”¨çš„NFLOWæ¡†æ¶ç›®æ ‡ä»¥è¾ƒå°‘çš„è®¡ç®—é‡æ”¶æ•›åˆ°ç›¸ä¼¼çš„ç»“æœã€‚
- We propose to use conditional normalizing flows for unsupervised anomaly detection with localization using computational and memory-efficient architecture.æˆ‘ä»¬å»ºè®®ä½¿ç”¨æœ‰æ¡ä»¶çš„æ ‡å‡†åŒ–æµç¨‹æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹ä¸å®šä½ä½¿ç”¨è®¡ç®—å’Œå†…å­˜é«˜æ•ˆçš„æ¶æ„ã€‚
- We show that our model outperforms previous stateof-the art in both detection and localization due to the unique properties of the proposed CFLOW-AD model.æˆ‘ä»¬è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨æ£€æµ‹å’Œå®šä½æ–¹é¢ä¼˜äºä»¥å‰çš„å…ˆè¿›æ°´å¹³ï¼Œå› ä¸ºæ‰€æå‡ºçš„CFLOW-ADæ¨¡å‹çš„ç‹¬ç‰¹æ€§è´¨ã€‚

#### 3. Theoretical background 

##### 3.1. Feature extraction with Gaussian prior

Consider a CNN h(Î») trained for classification task. Its parameters Î» are usually found by minimizing KullbackLeibler (DKL) divergence between joint train data distribution Qx,y and the learned model distribution Px,y(Î»), where (x, y) is an input-label pair for supervised learning.è€ƒè™‘ä¸ºåˆ†ç±»ä»»åŠ¡è®­ç»ƒçš„CNN h(Î»)ã€‚å®ƒçš„å‚æ•°Î»é€šå¸¸é€šè¿‡æœ€å°åŒ–è”åˆåˆ—è½¦æ•°æ®åˆ†å¸ƒQx,yå’Œå­¦ä¹ æ¨¡å‹åˆ†å¸ƒPx,y(Î»)ä¹‹é—´çš„KullbackLeibler (DKL)æ•£åº¦æ¥æ‰¾åˆ°ï¼Œå…¶ä¸­(x, y)ä¸ºç›‘ç£å­¦ä¹ çš„è¾“å…¥æ ‡ç­¾å¯¹ã€‚

Typically, the parameters Î» are initialized by the values sampled from the Gaussian distribution [12] and optimization process is regularized asï¼šé€šå¸¸ï¼Œå‚æ•°Î»ç”±å€¼åˆå§‹åŒ–é‡‡æ ·è‡ªé«˜æ–¯åˆ†å¸ƒ[12]ï¼Œä¼˜åŒ–è¿‡ç¨‹æ­£åˆ™åŒ–ä¸º

![image-20220104160015055](imgs/image-20220104160015055.png)

where R(Î») is a regularization term and Î± is a hyperparameter that defines regularization strength.å…¶ä¸­R(Î»)æ˜¯æ­£åˆ™é¡¹ï¼ŒÎ±æ˜¯å®šä¹‰æ­£åˆ™åŒ–å¼ºåº¦çš„è¶…å‚æ•°ã€‚



The most popular CNNs [13, 43] are trained with L2 weight decay [17] regularization (R(Î») = kÎ»k 2 2 ). That imposes multivariate Gaussian (MVG) prior not only to parameters Î», but also to the feature vectors z extracted from the feature maps of h(Î») [11] intermediate layers.æœ€æµè¡Œçš„cnn[13,43]æ˜¯ç”¨L2è®­ç»ƒçš„æ­£åˆ™åŒ–(R(Î») = kÎ»k22)ï¼ è¿™ä½¿å¾—å¤šå…ƒé«˜æ–¯(MVG)ä¸ä»…ä¼˜å…ˆäºå‚æ•°Î»ï¼Œè€Œä¸”ä¼˜å…ˆäºæå–çš„ç‰¹å¾å‘é‡zh(Î»)[11]ä¸­é—´å±‚çš„ç‰¹å¾å›¾ã€‚

##### 3.2. A case for Mahalanobis distance 

With the same MVG prior assumption, Lee et al. [18] recently proposed to model distribution of feature vectors z by MVG density function and to use Mahalanobis distance [23] as a confidence score in CNN classifiers. åœ¨ç›¸åŒçš„MVGå…ˆéªŒå‡è®¾ä¸‹ï¼ŒLeeç­‰äºº[18]æœ€è¿‘æå‡ºçš„ç‰¹å¾å‘é‡åˆ†å¸ƒæ¨¡å‹åˆ©ç”¨MVGå¯†åº¦å‡½æ•°ï¼Œåˆ©ç”¨Mahalanobisè·ç¦»[23]ä½œä¸ºCNNåˆ†ç±»å™¨çš„ç½®ä¿¡åˆ†æ•°ã€‚ Inspired by [18], Rippel et al. [29] adopt Mahalanobis distance for anomaly detection task since this measure determines a distance of a particular feature vector z to its MVG distribution. Consider a MVG distribution N (Âµ, Î£) with a density function pZ(z) for random variable z âˆˆ R D defined aså¯å‘é€šè¿‡[18]ï¼ŒRippelç­‰äºº[29]é‡‡ç”¨é©¬æ°è·ç¦»å¼‚å¸¸æ£€æµ‹ä»»åŠ¡ï¼Œå› ä¸ºè¯¥æµ‹åº¦å†³å®šäº†ç‰¹å®šç‰¹å¾å‘é‡zåˆ°å…¶MVGåˆ†å¸ƒçš„è·ç¦»ã€‚è€ƒè™‘ä¸€ä¸ªå…·æœ‰å¯†åº¦çš„MVGåˆ†å¸ƒN(Âµï¼ŒÎ£)å‡½æ•°pZ(z)å¯¹äºéšæœºå˜é‡zâˆˆRDå®šä¹‰ä¸º

![image-20220104160303169](imgs/image-20220104160303169.png)

where Âµ âˆˆ R D is a mean vector and Î£ âˆˆ R DÃ—D is a covariance matrix of a true anomaly-free density pZ(z). Then, the Mahalanobis distance M(z) is calculated asâˆˆRã€‚Dæ˜¯ä¸€ä¸ªå‡å€¼å‘é‡ï¼ŒÎ£âˆˆR DÃ—Dæ˜¯ä¸€ä¸ªçœŸæ­£çš„æ— å¼‚å¸¸å¯†åº¦pZ(z)çš„åæ–¹å·®çŸ©é˜µã€‚ç„¶åï¼Œè®¡ç®—é©¬æ°è·ç¦»M(z)ä¸º

![image-20220104160403713](imgs/image-20220104160403713.png)

Since the true anomaly-free data distribution is unknown, mean vector and covariance matrix from (3) are replaced by the estimates ÂµË† and Î£Ë† calculated from the empirical train dataset Dtrain. At the same time, density function pZËœ(z) of anomaly data has different ÂµËœ and Î£Ëœ statistics, which allows to separate out-of-distribution and indistribution feature vectors using M(z) from (3).ç”±äºçœŸæ­£çš„æ— å¼‚å¸¸æ•°æ®åˆ†å¸ƒæ˜¯æœªçŸ¥çš„ï¼Œå› æ­¤(3)çš„å‡å€¼å‘é‡å’Œåæ–¹å·®çŸ©é˜µè¢«ç”±ç»éªŒè®­ç»ƒæ•°æ®é›†Dtrainè®¡ç®—å‡ºçš„ä¼°è®¡ÂµË†å’ŒÎ£Ë†æ‰€ä»£æ›¿ã€‚åŒæ—¶ï¼Œå¼‚å¸¸æ•°æ®çš„å¯†åº¦å‡½æ•°pZ (z)å…·æœ‰ä¸åŒçš„Âµ~å’ŒÎ£ statisticsï¼Œå…è®¸ä½¿ç”¨M(z)ä»(3)ä¸­åˆ†ç¦»å‡ºéåˆ†å¸ƒç‰¹å¾å‘é‡å’Œåˆ†å¸ƒç‰¹å¾å‘é‡ã€‚



This framework with MVG distribution assumption shows its effectiveness in image-level anomaly detection task [29] and is adopted by the state-of-the-art PaDiM [8] model in pixel-level anomaly localization task.è¯¥æ¡†æ¶é‡‡ç”¨MVGåˆ†å¸ƒå‡è®¾è¡¨æ˜äº†è¯¥æ–¹æ³•åœ¨å›¾åƒçº§å¼‚å¸¸æ£€æµ‹ä¸­çš„æœ‰æ•ˆæ€§ä»»åŠ¡[29]ï¼Œè¢«æœ€å…ˆè¿›çš„padm[8]æ‰€é‡‡ç”¨åŸºäºåƒç´ çº§å¼‚å¸¸å®šä½ä»»åŠ¡çš„æ¨¡å‹ã€‚



##### 3.3. Relationship with the flow framework 

Dinh et al. [9] introduce a class of generative probabilistic models called normalizing flows. These models apply change of variable formula to fit an arbitrary density pZ(z) by a tractable base distribution with pU (u) density and a bijective invertible mapping g âˆ’1 : Z â†’ U. Then, the loglikelihood of any z âˆˆ Z can be estimated by

Dinhç­‰äºº[9]ä»‹ç»äº†ä¸€ç±»ç”Ÿæˆæ¦‚ç‡æ¨¡å‹ï¼Œç§°ä¸ºå½’ä¸€åŒ–æµã€‚è¿™äº›æ¨¡å‹åº”ç”¨å˜é‡å˜æ¢å…¬å¼ï¼Œå°†ä»»æ„å¯†åº¦pZ(z)æ‹Ÿåˆä¸ºä¸€ä¸ªå…·æœ‰pU (u)å¯†åº¦çš„å¯å¤„ç†åŸºåˆ†å¸ƒå’Œä¸€ä¸ªåŒå°„å¯é€†æ˜ å°„gâˆ’1:zâ†’uï¼Œåˆ™ä»»æ„zâˆˆzçš„å¯¹æ•°ä¼¼ç„¶å¯ç”±

![image-20220104160623913](imgs/image-20220104160623913.png)

where a sample u âˆ¼ pU is usually from standard MVG distribution (u âˆ¼ N (0, I)) and a matrix J = âˆ‡zg âˆ’1 (z, Î¸) is the Jacobian of a bijective invertible flow model (z = g(u, Î¸) and u = g âˆ’1 (z, Î¸)) parameterized by vector Î¸.

å…¶ä¸­æ ·æœ¬u ~ pUé€šå¸¸æ¥è‡ªæ ‡å‡†MVGåˆ†å¸ƒ(u ~ N (0, I))ï¼ŒçŸ©é˜µJ =âˆ‡zgâˆ’1 (zï¼Œ Î¸)æ˜¯ç”±å‘é‡Î¸å‚æ•°åŒ–çš„åŒå°„å¯é€†æµæ¨¡å‹(z = g(uï¼Œ Î¸)å’Œu = gâˆ’1 (zï¼Œ Î¸))çš„é›…å¯æ¯”çŸ©é˜µã€‚

The flow model g(Î¸) is a set of basic layered transformations with tractable Jacobian determinants. For example, log | det J| in RealNVP [9] coupling layers is a simple sum of layerâ€™s diagonal elements. These models are optimized using stochastic gradient descent by maximizing loglikelihood in (4). Equivalently, optimization can be done by minimizing the reverse DKL [Ë†pZ(z, Î¸)kpZ(z)] [27], where pË†Z(z, Î¸) is the model prediction and pZ(z) is a target density. The loss function for this objective is defined as

æµåŠ¨æ¨¡å‹g(Î¸)æ˜¯ä¸€ç»„å…·æœ‰å¯å¤„ç†é›…å¯æ¯”è¡Œåˆ—å¼çš„åŸºæœ¬å±‚å˜æ¢ã€‚ä¾‹å¦‚ï¼ŒRealNVP[9]è€¦åˆå±‚ä¸­çš„log | det J|æ˜¯å±‚å¯¹è§’çº¿å…ƒç´ çš„ç®€å•å’Œã€‚è¿™äº›æ¨¡å‹é‡‡ç”¨éšæœºæ¢¯åº¦ä¸‹é™æ³•ï¼Œé€šè¿‡æœ€å¤§åŒ–(4)ä¸­çš„å¯¹æ•°ä¼¼ç„¶æ¥ä¼˜åŒ–ã€‚åŒæ ·åœ°ï¼Œä¼˜åŒ–å¯ä»¥é€šè¿‡æœ€å°åŒ–åå‘DKL[Ë†pZ(zï¼Œ Î¸)kpZ(z)][27]æ¥å®Œæˆï¼Œå…¶ä¸­pË†z (zï¼Œ Î¸)ä¸ºæ¨¡å‹é¢„æµ‹ï¼ŒpZ(z)ä¸ºç›®æ ‡å¯†åº¦ã€‚æ­¤ç›®æ ‡çš„æŸå¤±å‡½æ•°å®šä¹‰ä¸º

![image-20220104160725496](imgs/image-20220104160725496.png)

If pZ(z) is distributed according to Section 3.1 MVG assumption, we can express (5) as a function of Mahalanobis distance M(z) using its definition from (3) as

å¦‚æœpZ(z)æ˜¯æ ¹æ®3.1èŠ‚MVGå‡è®¾åˆ†å¸ƒçš„ï¼Œæˆ‘ä»¬å¯ä»¥å°†(5)è¡¨ç¤ºä¸ºé©¬æ°è·ç¦»M(z)çš„å‡½æ•°ï¼Œç”±(3)å®šä¹‰ä¸º

![image-20220104160757783](imgs/image-20220104160757783.png)



where E2 (u) = kuk 2 2 is a squared Euclidean distance of a sample u âˆ¼ N (0, I) (detailed proof in Appendix A)

å…¶ä¸­E2 (u) = kuk 2æ˜¯æ ·æœ¬u ~ N (0, I)çš„å¹³æ–¹æ¬§å‡ é‡Œå¾·è·ç¦»(è¯¦ç»†è¯æ˜è§é™„å½•a)



Then, the loss in (6) converges to zero when the likelihood contribution term | det J| of the model g(Î¸) (normalized by det Î£âˆ’1/2 ) compensates the difference between a squared Mahalanobis distance for z from the target density and a squared Euclidean distance for u âˆ¼ N (0, I).

ç„¶åï¼Œå½“æ¨¡å‹g(Î¸)(é€šè¿‡det Î£âˆ’1/2å½’ä¸€åŒ–)çš„ä¼¼ç„¶è´¡çŒ®é¡¹| det J|è¡¥å¿zåˆ°ç›®æ ‡å¯†åº¦çš„é©¬æ°è·ç¦»çš„å¹³æ–¹å’Œu ~ N (0, I)çš„æ¬§æ°è·ç¦»çš„å¹³æ–¹ä¹‹é—´çš„å·®æ—¶ï¼Œ(6)çš„æŸå¤±æ”¶æ•›åˆ°é›¶ã€‚



This normalizing flow framework can estimate the exact likelihoods of any arbitrary distribution with pZ density, while Mahalanobis distance is limited to MVG distribution only. For example, CNNs trained with L1 regularization would have Laplace prior [11] or have no particular prior in the absence of regularization. Moreover, we introduce conditional normalizing flows in the next section and show that they are more compact in size and have fully-convolutional parallel architecture compared to [7, 8] models.

è¿™ç§å½’ä¸€åŒ–æµæ¡†æ¶å¯ä»¥ä¼°è®¡ä»»ä½•å…·æœ‰pZå¯†åº¦çš„ä»»æ„åˆ†å¸ƒçš„ç²¾ç¡®æ¦‚ç‡ï¼Œè€Œé©¬æ°è·ç¦»ä»…å±€é™äºMVGåˆ†å¸ƒã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨L1æ­£åˆ™åŒ–è®­ç»ƒçš„cnnï¼Œè¦ä¹ˆæœ‰æ‹‰æ™®æ‹‰æ–¯å…ˆéªŒ[11]ï¼Œè¦ä¹ˆåœ¨æ²¡æœ‰æ­£åˆ™åŒ–çš„æƒ…å†µä¸‹æ²¡æœ‰ç‰¹å®šå…ˆéªŒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨ä¸‹ä¸€èŠ‚ä¸­å¼•å…¥äº†æ¡ä»¶å½’ä¸€åŒ–æµï¼Œå¹¶è¡¨æ˜ä¸[7,8]æ¨¡å‹ç›¸æ¯”ï¼Œå®ƒä»¬åœ¨å°ºå¯¸ä¸Šæ›´ç´§å‡‘ï¼Œå¹¶å…·æœ‰å®Œå…¨å·ç§¯å¹¶è¡Œæ¶æ„ã€‚



![image-20220104160936220](imgs/image-20220104160936220.png)

Figure 2. Overview of our CFLOW-AD with a fully-convolutional translation-equivariant architecture. Encoder h(Î») is a CNN feature extractor with multi-scale pyramid pooling. Pyramid pooling captures both global and local semantic information with the growing from top to bottom receptive fields. Pooled feature vectors z k i are processed by a set of decoders gk(Î¸k) independently for each kth scale. Our decoder is a conditional normalizing flow network with a feature input z k i and a conditional input c k i with spatial information from a positional encoder (PE). The estimated multi-scale likelihoods p k i are upsampled to the input size and added up to produce anomaly map.

å›¾2ã€‚æˆ‘ä»¬çš„CFLOW-ADä¸å…¨å·ç§¯å¹³ç§»ç­‰å˜ç»“æ„çš„æ¦‚è¿°ã€‚ç¼–ç å™¨h(Î»)æ˜¯ä¸€ç§å¤šå°ºåº¦é‡‘å­—å¡”æ± åŒ–çš„CNNç‰¹å¾æå–å™¨ã€‚é‡‘å­—å¡”æ± æ•è·å…¨å±€å’Œå±€éƒ¨è¯­ä¹‰ä¿¡æ¯ï¼Œæ¥å—åŸŸä»ä¸Šåˆ°ä¸‹ä¸æ–­å¢é•¿ã€‚å¯¹äºæ¯ä¸ªç¬¬kä¸ªå°ºåº¦ï¼Œåˆå¹¶çš„ç‰¹å¾å‘é‡zkiç”±ä¸€ç»„è§£ç å™¨gk(Î¸k)ç‹¬ç«‹å¤„ç†ã€‚æˆ‘ä»¬çš„è§£ç å™¨æ˜¯ä¸€ä¸ªæ¡ä»¶å½’ä¸€åŒ–æµç½‘ç»œï¼Œç‰¹å¾è¾“å…¥zkiå’Œå¸¦æœ‰ç©ºé—´ä¿¡æ¯çš„æ¡ä»¶è¾“å…¥ckiæ¥è‡ªä½ç½®ç¼–ç å™¨(PE)ã€‚å°†ä¼°è®¡çš„å¤šå°ºåº¦ä¼¼ç„¶æ¦‚ç‡piä¸Šé‡‡æ ·åˆ°è¾“å…¥å¤§å°ï¼Œå¹¶ç›¸åŠ ç”Ÿæˆå¼‚å¸¸å›¾ã€‚



#### 4. The proposed CFLOW-AD model

#####  4.1. CFLOW encoder for feature extraction 

We implement a feature extraction scheme with multiscale feature pyramid pooling similar to recent models [7, 8]. We define the discriminatively-trained CNN feature extractor as an encoder h(Î») in Figure 2. æˆ‘ä»¬å®ç°äº†ä¸€ç§å¤šå°ºåº¦ç‰¹å¾é‡‘å­—å¡”æ± çš„ç‰¹å¾æå–æ–¹æ¡ˆï¼Œç±»ä¼¼äºæœ€è¿‘çš„æ¨¡å‹[7,8]ã€‚æˆ‘ä»¬å°†åŒºåˆ«è®­ç»ƒçš„CNNç‰¹å¾æå–å™¨å®šä¹‰ä¸ºå›¾2ä¸­çš„ç¼–ç å™¨h(Î»)ã€‚The CNN encoder maps image patches x into a feature vectors z that contain relevant semantic information about their content.CNNç¼–ç å™¨å°†å›¾åƒå—xæ˜ å°„ä¸ºä¸€ä¸ªç‰¹å¾å‘é‡zï¼Œè¯¥ç‰¹å¾å‘é‡åŒ…å«å…³äºå…¶å†…å®¹çš„ç›¸å…³è¯­ä¹‰ä¿¡æ¯ã€‚  CNNs accomplish this task efficiently due to their translation equivariant architecture with the shared kernel parameters.cnné«˜æ•ˆåœ°å®Œæˆäº†è¿™ä¸€ä»»åŠ¡ï¼Œå› ä¸ºå®ƒä»¬å…·æœ‰å…·æœ‰å…±äº«å†…æ ¸å‚æ•°çš„ç¿»è¯‘ç­‰å˜æ¶æ„ ã€‚ In our experiments, we use ImageNet-pretrained encoder following Schirrmeister et al. [34] who show that large natural-image datasets can serve as a representative distribution for pretraining. åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ç»§Schirrmeisterç­‰äºº[34]ä¹‹åçš„imageneté¢„è®­ç»ƒç¼–ç å™¨ï¼Œä»–ä»¬è¡¨æ˜å¤§å‹è‡ªç„¶å›¾åƒæ•°æ®é›†å¯ä»¥ä½œä¸ºé¢„è®­ç»ƒçš„ä»£è¡¨æ€§åˆ†å¸ƒã€‚If a large application-domain unlabeled data is available, the self-supervised pretraining from [42, 19] can be a viable option.å¦‚æœæœ‰å¤§é‡çš„åº”ç”¨åŸŸæœªæ ‡è®°æ•°æ®å¯ç”¨ï¼Œåˆ™[42,19]ä¸­çš„è‡ªæˆ‘ç›‘ç£é¢„è®­ç»ƒå¯ä»¥æ˜¯ä¸€ä¸ªå¯è¡Œçš„é€‰æ‹©ã€‚



One important aspect of a CNN encoder is its effective receptive field [21]. CNNç¼–ç å™¨çš„ä¸€ä¸ªé‡è¦æ–¹é¢æ˜¯å…¶æœ‰æ•ˆçš„æ¥æ”¶åŸŸ[21]ã€‚Since the effective receptive field is not strictly bounded, the size of encoded patches x cannot be exactly defined. ç”±äºæœ‰æ•ˆæ¥å—åŸŸä¸æ˜¯ä¸¥æ ¼æœ‰ç•Œçš„ï¼Œæ‰€ä»¥ä¸èƒ½ç²¾ç¡®åœ°å®šä¹‰ç¼–ç çš„patch xçš„å¤§å°ã€‚ At the same time, anomalies have various sizes and shapes, and, ideally, they have to be processed with the variable receptive fields. ä¸æ­¤åŒæ—¶ï¼Œå¼‚å¸¸æœ‰å„ç§å¤§å°å’Œå½¢çŠ¶ï¼Œç†æƒ³æƒ…å†µä¸‹ï¼Œå®ƒä»¬å¿…é¡»ç”¨å¯å˜çš„æ¥å—åŸŸå¤„ç†ã€‚ To address the ambiguity between CNN receptive fields and anomaly variability, we adopt common multi-scale feature pyramid pooling approach. ä¸ºäº†è§£å†³CNNæ¥å—åŸŸä¸å¼‚å¸¸å˜å¼‚æ€§ä¹‹é—´çš„æ¨¡ç³Šæ€§é—®é¢˜ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å¸¸ç”¨çš„å¤šå°ºåº¦ç‰¹å¾é‡‘å­—å¡”èåˆæ–¹æ³•ã€‚ Figure 2 shows that the feature vectors z k i âˆˆ R Dk , i âˆˆ {Hk Ã—Wk} are extracted by K pooling layers.å›¾2æ˜¾ç¤ºäº†ç”±kä¸ªæ± åŒ–å±‚æå–çš„ç‰¹å¾å‘é‡z k iâˆˆR Dk, iâˆˆ{Hk Ã—Wk}ã€‚ Pyramid pooling captures both local and global patch information with small and large receptive fields in the first and last CNN layers, respectively. é‡‘å­—å¡”æ± åˆ†åˆ«åœ¨CNNçš„ç¬¬ä¸€å±‚å’Œæœ€åä¸€å±‚ç”¨å°çš„å’Œå¤§çš„æ¥å—åŸŸæ•è·å±€éƒ¨å’Œå…¨å±€çš„patchä¿¡æ¯ã€‚For convenience, we number pooling layers in the last to first layer order.ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œæˆ‘ä»¬æŒ‰ç…§æœ€ååˆ°ç¬¬ä¸€å±‚çš„é¡ºåºç»™æ± åŒ–å±‚ç¼–å·ã€‚



##### 4.2. CFLOW decoders for likelihood estimation 

We use the general normalizing flow framework from Section 3.3 to estimate log-likelihoods of feature vectors z.  Hence, our generative decoder model g(Î¸) aims to fit true density pZ(z) by an estimated parameterized density pË†Z(z, Î¸) from (1). å› æ­¤ï¼Œæˆ‘ä»¬çš„ç”Ÿæˆè§£ç å™¨æ¨¡å‹g(Î¸)çš„ç›®æ ‡æ˜¯ç”¨(1)ä¸­ä¼°è®¡çš„å‚æ•°åŒ–å¯†åº¦pË†z (zï¼Œ Î¸)æ‹ŸåˆçœŸå®å¯†åº¦pZ(z)ã€‚However, the feature vectors are assumed to be independent of their spatial location in the general framework.  ç„¶è€Œï¼Œåœ¨ä¸€èˆ¬æ¡†æ¶ä¸­ï¼Œå‡è®¾ç‰¹å¾å‘é‡ç‹¬ç«‹äºå®ƒä»¬çš„ç©ºé—´ä½ç½®ã€‚To increase efficacy of distribution modeling, we propose to incorporate spatial prior into g(Î¸) model using conditional flow framework.ä¸ºäº†æé«˜åˆ†å¸ƒæ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬æå‡ºå°†ç©ºé—´å…ˆéªŒçº³å…¥ä½¿ç”¨æ¡ä»¶æµæ¡†æ¶çš„g(Î¸)æ¨¡å‹ã€‚In addition, we model pË† k Z (z, Î¸) densities using K independent decoder models gk(Î¸k) due to multi-scale feature pyramid pooling setup.æ­¤å¤–ï¼Œåˆ©ç”¨å¤šå°ºåº¦ç‰¹å¾é‡‘å­—å¡”æ± åŒ–æ–¹æ³•ï¼Œåˆ©ç”¨kä¸ªç‹¬ç«‹è§£ç å™¨æ¨¡å‹gk(Î¸k)å»ºç«‹äº†pË†kz (Zï¼Œ Î¸)å¯†åº¦æ¨¡å‹ã€‚



Our conditional normalizing flow (CFLOW) decoder architecture is presented in Figure 2. æˆ‘ä»¬çš„æ¡ä»¶å½’ä¸€åŒ–æµ(CFLOW)è§£ç å™¨æ¶æ„å¦‚å›¾2æ‰€ç¤ºã€‚ We generate a conditional vector c k i using a 2D form of conventional positional encoding (PE) [39]. æˆ‘ä»¬ä½¿ç”¨ä¼ ç»Ÿä½ç½®ç¼–ç (PE)[39]çš„äºŒç»´å½¢å¼ç”Ÿæˆæ¡ä»¶å‘é‡ckiã€‚ Each c k i âˆˆ R Ck contains sin and cos harmonics that are unique to its spatial location (hk, wk)i . æ¯ä¸ªCk iâˆˆR CkåŒ…å«å…¶ç©ºé—´ä½ç½®(hk, wk)iæ‰€ç‰¹æœ‰çš„sinå’Œcosè°æ³¢ã€‚We extend unconditional flow framework to CFLOW by concatenating the intermediate vectors inside decoder coupling layers with the conditional vectors ci as in [2].æˆ‘ä»¬å°†æ— æ¡ä»¶æµæ¡†æ¶æ‰©å±•åˆ°CFLOWï¼Œæ–¹æ³•æ˜¯å°†è§£ç å™¨è€¦åˆå±‚ä¸­çš„ä¸­é—´å‘é‡ä¸[2]ä¸­çš„æ¡ä»¶å‘é‡ciè¿æ¥èµ·æ¥ã€‚



Then, the kth CFLOW decoder contains a sequence of conventional coupling layers with the additional conditional input.ç„¶åï¼Œç¬¬kä¸ªCFLOWè§£ç å™¨åŒ…å«ä¸€ç³»åˆ—å¸¸è§„è€¦åˆå±‚å’Œé™„åŠ çš„æ¡ä»¶è¾“å…¥ã€‚ Each coupling layer comprises of fully-connected layer with (Dk+Ck)Ã—(Dk+Ck) kernel, softplus activation and output vector permutations. æ¯ä¸ªè€¦åˆå±‚ç”±(Dk+Ck)Ã—(Dk+Ck)æ ¸ã€è½¯åŠ æ¿€æ´»å’Œè¾“å‡ºè½½ä½“æ’åˆ—çš„å…¨è¿æ¥å±‚ç»„æˆã€‚ Usually, the conditional extension does not increase model size since Ck  Dk. For example, we use the fixed Ck = 128 in all our experiments. é€šå¸¸ï¼Œæ¡ä»¶æ‰©å±•ä¸ä¼šå¢åŠ æ¨¡å‹å¤§å°ï¼Œå› ä¸ºCk  Dkã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬åœ¨æ‰€æœ‰çš„å®éªŒä¸­éƒ½ä½¿ç”¨å›ºå®šçš„Ck = 128ã€‚Our CFLOW decoder has translation-equivariant architecture, because it slides along feature vectors extracted from the intermediate feature maps with kernel parameter sharing. æˆ‘ä»¬çš„CFLOWè§£ç å™¨å…·æœ‰å¹³ç§»ç­‰å˜ç»“æ„ï¼Œå› ä¸ºå®ƒæ²¿ç€ä»ä¸­é—´ç‰¹å¾æ˜ å°„ä¸­æå–çš„ç‰¹å¾å‘é‡æ»‘åŠ¨ï¼Œå¹¶å…±äº«å†…æ ¸å‚æ•°ã€‚As a result, both the encoder h(Î») and decoders gk(Î¸k) have convolutional translation-equivariant architectures.å› æ­¤ï¼Œç¼–ç å™¨h(Î»)å’Œè§£ç å™¨gk(Î¸k)éƒ½å…·æœ‰å·ç§¯å¹³ç§»ç­‰å˜ç»“æ„ã€‚



We train CFLOW-AD using a maximum likelihood objective, which is equivalent to minimizing loss defined byæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªæœ€å¤§ä¼¼ç„¶ç›®æ ‡æ¥è®­ç»ƒCFLOW-ADï¼Œè¿™ä¸ªç›®æ ‡ç­‰ä»·äºæœ€å°åŒ–ç”±å®šä¹‰çš„æŸå¤±

![image-20220104161931119](imgs/image-20220104161931119.png)

where the random variable ui = g âˆ’1 (zi , ci , Î¸), the Jacobian Ji = âˆ‡zg âˆ’1 (zi , ci , Î¸) for CFLOW decoder and an expectation operation in DKL is replaced by an empirical train dataset Dtrain of size N. For brevity, we drop the kth scale notation. The derivation is given in Appendix B.

éšæœºå˜é‡çš„ui = gâˆ’1(å­,ci,Î¸),é›…å¯æ¯”çŸ©é˜µéœ=âˆ‡zgâˆ’1(å­,ci,Î¸)CFLOWè¯‘ç å™¨å’Œä¸€ä¸ªæœŸæœ›æ“ä½œDKLè¢«å®è¯Dtrainè®­ç»ƒæ•°æ®é›†çš„å¤§å°nä¸ºç®€ä¾¿èµ·è§,æˆ‘ä»¬æŠŠkæ¯”ä¾‹ç¬¦å·ã€‚æ¨å¯¼åœ¨é™„å½•Bä¸­ç»™å‡ºã€‚



## 2. å­¦ä¹ è¿‡ç¨‹æ•´ç†

æœ¬å°èŠ‚æ˜¯è®ºæ–‡ä¸­3. Theoretical Backgroundå†…å®¹çš„è§£é‡Šã€‚

### 2.1 CNN

ç•¥

### 2.2 é©¬æ°è·ç¦»

å‚è€ƒï¼šhttps://github.com/FelixFu520/README/blob/main/train/loss/distance.md

### 2.3 INNï¼ˆå¯é€†ç½‘ç»œï¼‰

#### 2.3.1 æå®æ¯…è§†é¢‘-[Flow-based Generative Model](https://www.youtube.com/watch?v=uXY18nzdSsM)

##### ç”Ÿæˆæ¨¡å‹

![image-20220106195409416](imgs/image-20220106195409416.png)

![image-20220106195505954](imgs/image-20220106195505954.png)

![image-20220106200124764](imgs/image-20220106200124764.png)



![image-20220106200200131](imgs/image-20220106200200131.png)

##### Flow-based æ•°å­¦åŸºç¡€

![image-20220106200230708](imgs/image-20220106200230708.png)

###### é›…å¯æ¯”çŸ©é˜µæ˜¯ä»€ä¹ˆï¼Ÿ

![image-20220106200849564](imgs/image-20220106200849564.png)

###### è¡Œåˆ—å¼æ˜¯æ˜¯ä»€ä¹ˆï¼Ÿ

![image-20220106201040805](imgs/image-20220106201040805.png)

è¡Œåˆ—å¼çš„å«ä¹‰æ˜¯é¢ç§¯ã€ä½“ç§¯ã€...

![image-20220106201245363](imgs/image-20220106201245363.png)

###### ä»€ä¹ˆæ˜¯å˜åˆ†ï¼Ÿ

![image-20220106201426006](imgs/image-20220106201426006.png)

![image-20220106201639792](imgs/image-20220106201639792.png)

![image-20220106202126822](imgs/image-20220106202126822.png)

![image-20220106202433953](imgs/image-20220106202433953.png)

![image-20220107094505884](imgs/image-20220107094505884.png)

##### Flow-based Model

![image-20220107103436959](imgs/image-20220107103436959.png)

![image-20220107094652779](imgs/image-20220107094652779.png)

Flow-based Model è¾“å…¥å’Œè¾“å‡ºç»´åº¦ä¸€è‡´

![image-20220107104648187](imgs/image-20220107104648187.png)

![image-20220107104751927](imgs/image-20220107104751927.png)

![image-20220107104944766](imgs/image-20220107104944766.png)

![image-20220107105247399](imgs/image-20220107105247399.png)

![image-20220107105502242](imgs/image-20220107105502242.png)

å¦‚ä½•é€†å‘å‘¢ï¼Ÿ

![image-20220107105609830](imgs/image-20220107105609830.png)

å¦‚ä½•è®¡ç®—é›…å¯æ¯”çš„è¡Œåˆ—å¼å‘¢ï¼Ÿ

![image-20220107110014405](imgs/image-20220107110014405.png)

![image-20220107110132772](imgs/image-20220107110132772.png)

é’ˆå¯¹å›¾åƒï¼Œå¦‚ä½•æ‹†å‘¢ï¼Ÿ

![image-20220107110309321](imgs/image-20220107110309321.png)

![image-20220107110725955](imgs/image-20220107110725955.png)

![image-20220107110933799](imgs/image-20220107110933799.png)

![image-20220107111156314](imgs/image-20220107111156314.png)

![image-20220107111258391](imgs/image-20220107111258391.png)

![image-20220107111359386](imgs/image-20220107111359386.png)

![image-20220107111410726](imgs/image-20220107111410726.png)

Glowç”¨æ¥åšè¯­éŸ³åˆæˆæ¯”è¾ƒå¤š

![image-20220107111427896](imgs/image-20220107111427896.png)

#### 2.3.2 æŠ€æœ¯å–µè§†é¢‘ 

[ç¥ç»ç½‘ç»œ(åäº”ï¼‰æ ‡å‡†åŒ–æµ(normalizing flow) ä¸INN (Invertible Neural Networks)](https://www.youtube.com/watch?v=1qPaDhR2uMY)

![image-20220107111711950](imgs/image-20220107111711950.png)

![image-20220107112717513](imgs/image-20220107112717513.png)

![image-20220107112728262](imgs/image-20220107112728262.png)

![image-20220107112942250](imgs/image-20220107112942250.png)

![image-20220107113150142](imgs/image-20220107113150142.png)

![image-20220107113312965](imgs/image-20220107113312965.png)

![image-20220107113405094](imgs/image-20220107113405094.png)

![image-20220107113624481](imgs/image-20220107113624481.png)

![image-20220107113800828](imgs/image-20220107113800828.png)

æµå‡½æ•°æ˜¯æ„æˆNFçš„åŸºæœ¬æ„ä»¶ï¼Œé‚£ä¹ˆå¦‚ä½•é€‰æ‹©æµå‡½æ•°å‘¢ï¼Ÿ

![image-20220107113943919](imgs/image-20220107113943919.png)

![image-20220107114023476](imgs/image-20220107114023476.png)

![image-20220107114221309](imgs/image-20220107114221309.png)

![image-20220107114445826](imgs/image-20220107114445826.png)

![image-20220107114748437](imgs/image-20220107114748437.png)

![image-20220107114833548](imgs/image-20220107114833548.png)

![image-20220107114911528](imgs/image-20220107114911528.png)

![image-20220107115043575](imgs/image-20220107115043575.png)

![image-20220107115108144](imgs/image-20220107115108144.png)

![image-20220107115236391](imgs/image-20220107115236391.png)

normalizing flowçš„æœ¬è´¨æ˜¯è¾“å…¥æ˜¯åˆ†å¸ƒï¼Œè¾“å‡ºæ˜¯åˆ†å¸ƒï¼Œä½†æ˜¯å®é™…ä¸Šï¼Œæˆ‘ä»¬æ‹¿åˆ°çš„éƒ½æ˜¯æ•°å­—ä¿¡å·ï¼Œéƒ½æ˜¯ç¦»æ•£çš„ï¼Œæ‰€ä»¥ä¸æ˜¯æ¨¡æ‹Ÿä¿¡å·ï¼Œè¿™ç§æƒ…å†µä¸‹ï¼Œå¯¹æˆ‘ä»¬æƒ³è¦ä½ å’Œçš„è¿™ä¸ªåˆ†å¸ƒï¼Œä¼šäº§ç”Ÿä¸€å®šçš„æ‰­æ›²ï¼Œæ‰€ä»¥é€šå¸¸åŠ ä¸€æ­¥dequantiazationï¼ˆåé‡åŒ–ï¼‰ã€‚

![image-20220107115639552](imgs/image-20220107115639552.png)

è®ºæ–‡æ¨èï¼š L. Dinh, D. Krueger, and Y. Bengio, â€œNICE: Non-linear Independent Components Estimation,â€ in ICLR Workshop, 2015 L. Dinh, J. Sohl-Dickstein, and S. Bengio, â€œDensity Estima-tion using Real NVP,â€ in ICLR, 2017. D. P. Kingma and P. Dhariwal, â€œGlow: Generative flow with invertible 1x1 convolutions,â€ in Advances in Neural Information Processing Systems, 2018  J. Ho, X. Chen, A. Srinivas, Y. Duan, and P. Abbeel, â€œFlow++: Improving flow-based generative models with variational dequantization and architecture design,â€ in Proceedings of the 36th International Conference on Machine Learning, ICML, 2019.  J. Behrmann, D. Duvenaud, and J.-H. Jacobsen, â€œInvertible residual networks,â€ in Proceedings of the 36th International Conference on Machine Learning, ICML, 2019.  C.-W. Huang, D. Krueger, A. Lacoste, and A. Courville, â€œNeural Autoregressive Flows,â€ in ICML, 2018  W. Grathwohl, R. T. Q Chen, J. Bettencourt, I. Sutskever, and D. Duvenaud, â€œFFJORD: Free-form continuous dynamics for scalable reversible generative models,â€ in ICLR, 2019 å…¶å®ƒå‚è€ƒèµ„æ–™ [1] Normalizing Flows: An Introduction and Review of Current Methods [2] Introduction to Normalizing Flows (ECCV2020 Tutorial and cvpr 2021 tutorial) by Marcus Brubaker [3] LiLian Wengâ€™s blog [https://lilianweng.github.io/lil-log/...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbWZvWndSUW54UzNWdy1aVTRTaUdnbThjZnVYUXxBQ3Jtc0trU0ZfamdETnFzQXBnVUd2cWhwNlkwLVc4cU1CYU5IakRCYnJQN3NJRDRHcWs4YjE4ZjNhVXVvU3RrVU9qRG5LTF9uQ3FkRExYNE5DR3FKdEpFc0dsOEhjaWE3REYwSnJBTzQ5a216LTVDTTNiRjM0Zw&q=https%3A%2F%2Flilianweng.github.io%2Flil-log%2F2018%2F10%2F13%2Fflow-based-deep-generative-models.html) [4] [https://github.com/janosh/awesome-nor...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbVU0SWRHUkhoQmg5WGVYZlMxMXdOcnkxVzBfd3xBQ3Jtc0ttX3Z3ZjczUURCeERuUUd6MmhGUzFJLWxudHRQMVNoTVhOSUs0TnZubnMweVlJNHU1VU5oT3plNDJiUlV6SjRwNkp1TWF1Ujc5M29nTHVFaDZEQnNqcFpXSU1wUUkxcVkzQnozM24wUjZKVElTQ2VDbw&q=https%3A%2F%2Fgithub.com%2Fjanosh%2Fawesome-normalizing-flows)